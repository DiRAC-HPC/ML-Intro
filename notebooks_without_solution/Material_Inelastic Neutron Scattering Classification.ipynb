{"cells": [{"cell_type": "markdown", "metadata": {"id": "CDgXQgxXzUhW"}, "source": ["# 0. Inelastic Neutron Scattering classification using Convolutional Neural Networks (CNNs)\n", "\n", "In this notebook, we attempt to identify if an image represents Dimer or Goodenough Hamiltonian\n", "\n", "Inelastic neutron scattering (INS) can be used to infer information about the forces present in a material. Neutrons scatter off a sample, exchanging energy with certain fundamental vibrational modes of the sample. These vibraional modes include phonons (interatomic boding forces) and magnons (spin coupling between magnetic nuclei). \n", "\n", "[Johnstone et al. (2012)](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.109.237202) have simulated magnon spectra from a double perovskite systems, where INS was used to distinguish between two possible magnetic Hamiltonians of the system. For this practical, we have simulated datasets for each of the possible Hamiltonians. \n", "\n", "The aim of this work is to build CNN to classify the system correctly."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 5765, "status": "ok", "timestamp": 1648565529327, "user": {"displayName": "Jaehoon Cha", "userId": "15142223743084603318"}, "user_tz": -60}, "id": "UdkKgKvOzUhc", "outputId": "81e72f3c-8fac-4d60-de8e-707d0ea3d291"}, "outputs": [], "source": ["# tensorflow\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\n", "from tensorflow.keras.callbacks import EarlyStopping\n", "\n", "# check version\n", "print('Using TensorFlow v%s' % tf.__version__)\n", "acc_str = 'accuracy' if tf.__version__[:2] == '2.' else 'acc'\n", "\n", "# helpers\n", "import h5py\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from os.path import join\n", "\n", "# need some certainty in data processing\n", "np.random.seed(1234)\n", "tf.random.set_seed(1234)\n"]}, {"cell_type": "markdown", "metadata": {"id": "Sc5Wod-M1xEU"}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "V_MOJqhN1yBo"}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 14925, "status": "ok", "timestamp": 1648565558956, "user": {"displayName": "Jaehoon Cha", "userId": "15142223743084603318"}, "user_tz": -60}, "id": "wP0G-zIL1ziV", "outputId": "bf4774ce-5fa9-4d98-90fc-e6add1c74314"}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "metadata": {"id": "-j_UYek2131z"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "1p2I5pLwzUhe"}, "source": ["# 1. Load the dataset\n", "\n", "### Read raw data\n", "\n", "We have already split the data into training and validation sets and saved them into two HDF5 files, `ins-data/train.h5` and `ins-data/test.h5`, containing respectively 20,000 and 6,676 INS images and their one-hot encoded labels identifying an image as either being of the *Dimer* or *Goodenough* Hamiltonian. "]}, {"cell_type": "markdown", "metadata": {"id": "uhqwE7EEzUhf"}, "source": ["### The `tf.data.Dataset` class\n", "The number of images is so large that we may not be able to simultaneously load the whole dataset into memory on a small machine. To solve this issue, we will use [tensorflow.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) to create an interface pointing to the files, which can load the data from disk on the fly when they are actually required."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 341, "status": "ok", "timestamp": 1648565559289, "user": {"displayName": "Jaehoon Cha", "userId": "15142223743084603318"}, "user_tz": -60}, "id": "OIX0WH9VzUhf", "outputId": "e56b630a-a54d-4746-cac0-c541313e5851"}, "outputs": [], "source": ["# define image size\n", "IMG_HEIGHT = 20\n", "IMG_WIDTH = 200\n", "N_CHANNELS = 1\n", "N_CLASSES = 2\n", "\n", "# generator\n", "def hdf5_generator(path, buffer_size=32):\n", "    \"\"\" Load data INS data from disk\n", "    \n", "    Args:\n", "        path: path of the HDF5 file on disk\n", "        buffer_size: number of images to read from disk\n", "    \"\"\"\n", "    with h5py.File(path, 'r') as handle:\n", "        n_samples, h, w, c = handle['images'].shape\n", "        for i in range(0, n_samples, buffer_size):\n", "            images = handle['images'][i:i+buffer_size, ..., :1]\n", "            labels = handle['labels'][i:i+buffer_size]\n", "            yield images, labels\n", "\n", "# training data\n", "train_dataset = tf.data.Dataset.from_generator(lambda: hdf5_generator(path=join(data_path,'ins-data/train.h5')), \n", "                                               output_types=(tf.float32, tf.float32),\n", "                                               output_shapes=((None, IMG_HEIGHT, IMG_WIDTH, N_CHANNELS), \n", "                                                              (None, N_CLASSES,)))\n", "\n", "# test data\n", "test_dataset = tf.data.Dataset.from_generator(lambda: hdf5_generator(path=join(data_path,'ins-data/test.h5')), \n", "                                              output_types=(tf.float32, tf.float32),\n", "                                              output_shapes=((None, IMG_HEIGHT, IMG_WIDTH, N_CHANNELS), \n", "                                                             (None, N_CLASSES,)))\n", "# print\n", "print(train_dataset)\n", "print(test_dataset)"]}, {"cell_type": "markdown", "metadata": {"id": "uOf0FXMfzUhg"}, "source": ["### Load and visualize data\n", "\n", "In the following cell, we will load the first buffer (with 32 data by default) to memory and plot some images and labels from it:\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# load the first buffer (with 32 data by default)\n", "images, labels = list(test_dataset.take(1))[0]\n", "\n", "# plot some images and labels from it\n", "nplot = 10\n", "fig, axes = plt.subplots(nplot // 2, 2, figsize=(16, nplot / 1.5), dpi=100)\n", "for ax, image, label in zip(axes.flatten(), images, labels):\n", "    ax.matshow(np.squeeze(image))\n", "    ax.set_xlabel('0: Dimer' if label[0] < .5 else '1: Goodenough', c='k')\n", "    ax.set_xticks([])\n", "    ax.set_yticks([])\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 534}, "executionInfo": {"elapsed": 1215, "status": "ok", "timestamp": 1648565560501, "user": {"displayName": "Jaehoon Cha", "userId": "15142223743084603318"}, "user_tz": -60}, "id": "g2TW6KQ7zUhg", "outputId": "0af9b35a-6573-4e49-9e09-12de6a32f33c"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "AcxChZy6zUhh"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "Unu7UNWIzUhh"}, "source": ["# 2. Build the network\n", "\n", "The task is to build and train a CNN to solve this binary classification problem. \n", "\n", "### Network architecture\n", "\n", "First, design the network architecture. Note that the image height is quite small, so we need to preserve the image size by passing `padding='same'` to `Conv2D`. A suggested architecture is provided:\n", "\n", "- Conv2D\n", " - 8 filters\n", " - kernel size 5$\\times$5\n", " - ReLU activation\n", "- MaxPool2D \n", "- BatchNormalization\n", "- Conv2D \n", " - 16 filters\n", " - kernel size 3$\\times$3\n", " - ReLU activation\n", "- MaxPool2D\n", "- BatchNormalization\n", "- Conv2D \n", " - 16 filters\n", " - kernel size 3$\\times$3\n", " - ReLU activation\n", "- MaxPool2D\n", "- BatchNormalization\n", "- Flatten \n", "- Dense\n", " - 16 units\n", " - ReLU activation\n", "- Dense\n", " - 8 units\n", " - ReLU activation\n", "- Dense\n", " - 1 unit\n", " - sigmoid activation\n", "\n", "\n", "     \n", "     \n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# network architecture\n", "model = Sequential()\n", "model.add(Conv2D(8, kernel_size=(5, 5), activation='relu', padding='same',\n", "                 input_shape=(IMG_HEIGHT, IMG_WIDTH, N_CHANNELS)))\n", "model.add(MaxPool2D(pool_size=(2, 2)))\n", "model.add(BatchNormalization())\n", "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'))\n", "model.add(MaxPool2D(pool_size=(2, 2)))\n", "model.add(BatchNormalization())\n", "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'))\n", "model.add(MaxPool2D(pool_size=(2, 2)))\n", "model.add(BatchNormalization())\n", "model.add(Flatten())\n", "model.add(Dense(16, activation='relu'))\n", "model.add(Dense(8, activation='relu'))\n", "model.add(Dense(N_CLASSES, activation='sigmoid'))\n", "\n", "# print summary\n", "model.summary()\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 306, "status": "ok", "timestamp": 1648565560785, "user": {"displayName": "Jaehoon Cha", "userId": "15142223743084603318"}, "user_tz": -60}, "id": "b24XH6AbzUhi", "outputId": "be3667e1-f91a-4f1e-ea42-93c1f6092533"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "QVKtDfIjzUhi"}, "source": ["### Compile the model\n", "\n", "We can add the following metrics to see how the network performs for the two classes:\n", "\n", "* `TruePositives`: number of right predictions for Dimer\n", "* `FalsePositives`: number of wrong predictions for Dimer\n", "* `TrueNegatives`: number of right predictions for Goodenough\n", "* `FalseNegatives`: number of wrong predictions for Goodenough\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# compile the model\n", "model.compile(optimizer='adam', loss='binary_crossentropy', \n", "              metrics= ['accuracy',\n", "                        keras.metrics.TruePositives(name='true_positives'),\n", "                        keras.metrics.FalsePositives(name='false_positives'),\n", "                        keras.metrics.TrueNegatives(name='true_negatives'),\n", "                        keras.metrics.FalseNegatives(name='false_negatives')])\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "6lHLTVy8zUhj"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "8aPtFuxszUhj"}, "source": ["### Train the model\n", "We train the model using our training data and after each full pass of the training data (an epoch), we evaluate it on the test data. We repeat this process until the validation loss stops decreasing.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# train the model\n", "stopper=EarlyStopping( monitor =\"val_loss\", min_delta=0.0,verbose=1,\n", "                      mode=\"min\",\n", "                      restore_best_weights=True,patience=2)\n", "\n", "\n", "training_history = model.fit(train_dataset, validation_data=test_dataset, \n", "                             epochs=10, batch_size=128,callbacks=[stopper])\n", "\n", "# print final values of metrics for validation data\n", "print('Right for Dimer: %d' % training_history.history['val_true_positives'][-1])\n", "print('Wrong for Dimer: %d' % training_history.history['val_false_positives'][-1])\n", "print('Right for Goodenough: %d' % training_history.history['val_true_negatives'][-1])\n", "print('Wrong for Goodenough: %d' % training_history.history['val_false_negatives'][-1])\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 647592, "status": "ok", "timestamp": 1648566208375, "user": {"displayName": "Jaehoon Cha", "userId": "15142223743084603318"}, "user_tz": -60}, "id": "qE8dWky4zUhj", "outputId": "cf9b7f6e-56d5-42c8-eb02-a6240d353d46"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "YPkl7Lyx2i23"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "w5trH_6z2h2R"}, "source": ["# 3. Analyse results "]}, {"cell_type": "markdown", "metadata": {"id": "mjVmQMGT3CYH"}, "source": ["### Plot training history\n", "\n", "For convenience, we define a function to plot a training history:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "lXe1mFL92kXH"}, "outputs": [], "source": ["# a function to plot training history\n", "def plot_history(training_history):\n", "    # plot accuracy\n", "    plt.figure(dpi=100, figsize=(12, 4))\n", "    plt.subplot(1, 2, 1)\n", "    plt.plot(training_history.history[acc_str], label='Accuracy on training data')\n", "    plt.plot(training_history.history['val_' + acc_str], label='Accuracy on test data')\n", "    plt.legend()\n", "    plt.title(\"Accuracy\")\n", "\n", "    # plot loss\n", "    plt.subplot(1, 2, 2)\n", "    plt.plot(training_history.history['loss'], label='Loss on training data')\n", "    plt.plot(training_history.history['val_loss'], label='Loss on test data')\n", "    plt.legend()\n", "    plt.title(\"Loss\")\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {"id": "jO4w8Qk73G9i"}, "source": ["Now, plot the training history of the current model. They will look bizarre at this stage, as explained in the forthcoming section.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# plot training history\n", "plot_history(training_history)\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 385}, "executionInfo": {"elapsed": 15690, "status": "ok", "timestamp": 1648566224061, "user": {"displayName": "Jaehoon Cha", "userId": "15142223743084603318"}, "user_tz": -60}, "id": "EsilxER53Ei5", "outputId": "f2388153-470d-4d2f-cd8e-cb16857be05b"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "F03hRLuO3LaX"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "K9m7PQ5tzUhj"}, "source": ["# 4. Exercises\n", "\n", "* Change some hyperparameters in `model.compile()` and `model.fit()` to see their effects (see reference of [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)); \n", "* Change the architeture and activation functions of neural networks to improve the accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "EvrcFXVTzUhj"}, "outputs": [], "source": []}], "metadata": {"colab": {"collapsed_sections": [], "name": "Material_Inelastic neutron scattering classification_solution.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 0}