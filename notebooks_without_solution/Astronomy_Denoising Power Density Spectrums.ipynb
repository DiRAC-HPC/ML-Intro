{"cells": [{"cell_type": "markdown", "id": "3b47979e", "metadata": {}, "source": ["# 0. Denoising power density spectrum using convolutional autoencoders.\n", "\n", "In this notebook, we attempt to remove noise in power density spectrum of Kepler red giant using convolutional autoencoders.\n", "\n", "[The Kepler mission](https://www.science.org/doi/10.1126/science.1185402) was designed to determine the frequency of Earth-sized planets in and near the habitable zone of Sun-like stars. Some of the most fundamental studies are to identify which stars show oscillations and to locate the frequency at maximum power. However, these studies are suffer from noise in signals. \n", "\n", "The aim of this work is to use a very deep convolutional autoencoder to remove noise in power density spectrum of Kepler red giant.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "id": "c9d73ba4", "metadata": {}, "outputs": [], "source": ["# tensorflow\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras import layers\n", "\n", "# check version\n", "print('Using TensorFlow v%s' % tf.__version__)\n", "acc_str = 'accuracy' if tf.__version__[:2] == '2.' else 'acc'\n", "\n", "# helpers\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import h5py\n", "import pickle\n", "from sklearn.model_selection import train_test_split\n", "from os.path import join\n", "\n", "# need some certainty in data processing\n", "np.random.seed(1234)\n", "tf.random.set_seed(1234)"]}, {"cell_type": "markdown", "id": "1b94483d", "metadata": {}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "id": "05b1e90c", "metadata": {}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "id": "d11f3c8b", "metadata": {}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "id": "463c9fd8", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "16225c69", "metadata": {}, "source": ["# 1. Load the dataset\n", "\n", "### Read raw data\n", "\n", "The data is stored in 'Astronomy/kepler.pickle', containing 6175 power density spectrum of Kepler red giant. The data has been preprocessed a bit using logarithm and median of each sample - so the values are between 0 and 2. \n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "data_path = join(data_path,'Astronomy/kepler.pickle')\n", "with open(data_path, 'rb') as f:\n", "    x_train = pickle.load(f)[0][:, :2**15] \n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "6a52df1b", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "0649f0cf", "metadata": {}, "outputs": [], "source": ["x_train = np.expand_dims(x_train, -1)\n", "print(x_train.shape)"]}, {"cell_type": "code", "execution_count": null, "id": "230ec3c8", "metadata": {}, "outputs": [], "source": ["idxs = np.random.choice(len(x_train), 8)\n", "\n", "fig, ax = plt.subplots(2, 4, figsize = (18, 9))\n", "for j in range(2):\n", "    for i in range(4):\n", "        ax[j, i].plot(x_train[idxs[i*2+j]].reshape(-1))\n", "        ax[j, i].set_title('Kepler ID: {}'.format(idxs[i*2+j]))\n", "\n", "fig.suptitle('Examples', y = 0.95)"]}, {"cell_type": "markdown", "id": "8496ae3d", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "4e5899b4", "metadata": {}, "source": ["# 2. Build the network\n", "\n", "The task is to build and train a convolutional autoencoder to remove noise in signals. The signals are 1D array, hence, we use 1D convolution in an encoder and 1D transposed convolution in a decoder."]}, {"cell_type": "markdown", "id": "e44ff82d", "metadata": {}, "source": ["### The encoder\n", "\n", "The encoder contains five 1D convolutional layers, an input layer with size 32768$\\times$1 and one dense layer with size 32:\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# build the encoder\n", "image_input = keras.Input(shape=(32768, 1))\n", "#x = layers.Flatten()(image_input)\n", "x = layers.Conv1D(8, 7, 4, padding = 'same')(image_input)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.LeakyReLU()(x)\n", "x = layers.Conv1D(16, 5, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.Conv1D(16, 5, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.LeakyReLU()(x)\n", "x = layers.Conv1D(32, 5, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.LeakyReLU()(x)\n", "x = layers.Conv1D(32, 5, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.LeakyReLU()(x)\n", "\n", "\n", "x = layers.Activation('relu')(x)\n", "x = layers.Flatten()(x)\n", "latent_output = layers.Dense(32)(x)\n", "encoder_AE = keras.Model(image_input, latent_output)\n", "encoder_AE.summary()\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "1ce93899", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "51dd343a", "metadata": {}, "source": ["### The decoder\n", "\n", "The decoder contains sixe transposed convolutional layers and one dense layer that are reciprocal to those of the encoders and one convolutional layer, outputing denoised signals with the same size as the input signals:\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# build the decoder\n", "latent_input = keras.Input(shape=(32))\n", "x = layers.Dense(16384)(latent_input)\n", "x = layers.Reshape((512, 32), input_shape=(16384,))(x)\n", "x = layers.Conv1DTranspose(32, 5, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.LeakyReLU()(x)\n", "x = layers.Conv1DTranspose(32, 5, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.LeakyReLU()(x)\n", "x = layers.Conv1DTranspose(16, 5, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.LeakyReLU()(x)\n", "x = layers.Conv1DTranspose(16, 5, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.LeakyReLU()(x)\n", "x = layers.Conv1DTranspose(8, 5, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.LeakyReLU()(x)\n", "x = layers.Conv1DTranspose(8, 5, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.LeakyReLU()(x)\n", "image_output = layers.Conv1D(1, 3, padding = 'same')(x)\n", "\n", "decoder_AE = keras.Model(latent_input, image_output)\n", "decoder_AE.summary()\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "7c99ed27", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "52cef4bd", "metadata": {}, "source": ["### The autoencoder\n", "\n", "Joining up the encoder and the decoder, we obtain the AE network:\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# build the AE\n", "image_input = keras.Input(shape=(32768, 1))\n", "latent = encoder_AE(image_input)\n", "image_output = decoder_AE(latent)\n", "ae_model = keras.Model(image_input, image_output)\n", "ae_model.summary()\n", "\n", "# compile the AE\n", "ae_model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "fa43fb0e", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "28dd9067", "metadata": {}, "outputs": [], "source": ["# train the AE\n", "ae_model.fit(x_train, x_train, epochs=50, batch_size=64)\n", "            "]}, {"cell_type": "markdown", "id": "4bb86482", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "838d1333", "metadata": {}, "source": ["# 3. Analyse results "]}, {"cell_type": "markdown", "id": "1d3b9cfe", "metadata": {}, "source": ["### Visualize the original signals and denoised signals by AE\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "idxs = [2000, 200, 5959, 1721, 123, 4231, 911, 6127]\n", "\n", "y = ae_model.predict(x_train[idxs])\n", "\n", "fig, ax = plt.subplots(2, 4, figsize = (18, 9))\n", "for j in range(2):\n", "    for i in range(4):\n", "        ax[j, i].plot(x_train[idxs[i*2+j]].reshape(-1), label = 'orignal signal')\n", "        ax[j, i].plot(y[i*2+j].reshape(-1), label = 'denoised signal')\n", "        ax[j, i].set_title('Kepler ID: {}'.format(idxs[i*2+j]))\n", "        ax[j, i].legend(loc = 1)\n", "\n", "fig.suptitle('examples', y = 0.95)\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "a9e39196", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "f4c8d9d1", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "bbdda32a", "metadata": {}, "source": ["# 4. Exercises\n", "\n", "* Change some hyperparameters in `model.compile()` and `model.fit()` to see their effects (see reference of [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)); \n", "* Change the architeture and activation functions of neural networks to improve the performance\n", "* Add noise to input layer to make the network more robust to noise"]}, {"cell_type": "code", "execution_count": null, "id": "cace9696", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}