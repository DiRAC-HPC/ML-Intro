{"cells": [{"cell_type": "markdown", "metadata": {"id": "FCHbWpQgIBbH"}, "source": ["# 0. Ferromagnetic phase and paramagnetic phase classification\n", "\n", "In this notebook, we attempt to classify the  ferromagnetic phase and the  paramagnetic phase. \n", "\n", "The Ising model is a mathematical model of ferromagnetism in statistical mechanics. The model consists of discrete variables that represent magnetic dipole moments of atomic \"spins\" that can be in one of two states (+1 or \u22121).\n", "\n", "Below a certain temperature called the Curie temperature, $T_c$, most of the spins are parallel, which results in a uniform overall state characterised by $+1$ or $-1$. This phase is called the ferromagnetic phase. Above $T_c$, magnetic dipole moments of half of the atomic \"spins\" yield $+1$ while the other half yields $-1$. This phase is called the paramagnetic phase. \n", "\n", "This work aims to classify two different types of magnetic phases: a low-temperature ferromagnetic phase and a high-temperature paramagnetic phase. The details can be found in [Machine learning phases of matter](https://doi.org/10.1038/nphys4035). "]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 215, "status": "ok", "timestamp": 1646400786882, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "ZlRgYuK1IBbK", "outputId": "c37ba266-c58b-4193-9bbf-8130343fdcc3"}, "outputs": [], "source": ["# tensorflow\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\n", "from tensorflow.keras.callbacks import EarlyStopping\n", "\n", "# check version\n", "print('Using TensorFlow v%s' % tf.__version__)\n", "acc_str = 'accuracy' if tf.__version__[:2] == '2.' else 'acc'\n", "\n", "# helpers\n", "import h5py\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from os.path import join\n", "\n", "# need some certainty in data processing\n", "np.random.seed(1234)\n", "tf.random.set_seed(1234)\n"]}, {"cell_type": "markdown", "metadata": {"id": "jO5JuRWIIBbM"}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "C5lZabhVIBbO"}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 15157, "status": "ok", "timestamp": 1646400734395, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "Gh5jcqmkIBbO", "outputId": "437359c5-26fa-4ad9-fc90-2d8ff872348d"}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "metadata": {"id": "z6V4dgeiIBbP"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "rwQ6T23aIBbP"}, "source": ["# 1. Load the dataset\n", "\n", "### Read raw data\n", "\n", "The data is stored in 'Physics/ising_data.npz', containing 26000, gray-scale, 32 \u00d7 32 images of the magnetic phases. We will use 20000 images to train neural networks and the rest of them to evaluate the neural networks.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "f = np.load(join(data_path, 'Physics/ising_data.npz'))\n", "n_train = 20000\n", "\n", "x_train, x_test = f[\"C\"][:n_train], f[\"C\"][n_train:]\n", "T_train, T_test = f[\"T\"][:n_train], f[\"T\"][n_train:]\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 1467, "status": "ok", "timestamp": 1646400759663, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "c3lsqkShIBbQ", "outputId": "385e49af-4931-4549-bf89-8b29bd9e65c2"}, "outputs": [], "source": ["# define image size\n", "IMG_HEIGHT = 32\n", "IMG_WIDTH = 32\n", "N_CHANNELS = 1\n", "N_CLASSES = 2\n", "\n", "### normalize data\n", "x_train = (x_train + 1)/2.\n", "x_test = (x_test + 1)/2.\n", "x_train = x_train.reshape(-1, 32, 32, 1)\n", "x_test = x_test.reshape(-1, 32, 32, 1)\n", "\n", "Tc = 2.27\n", "y_train, y_test = T_train > Tc, T_test > Tc\n", "\n", "string_labels = ['paramagnetic','ferromagnetic']\n", "\n", "# print\n", "print(\"Number of training data: %d\" % len(x_train))\n", "print(\"Number of test data: %d\" % len(x_test))\n", "print(\"Image pixels: %s\" % str(x_train[0, :, :, 0].shape))\n", "print(\"Number of channels: %s\" % str(x_train.shape[-1]))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 739}, "executionInfo": {"elapsed": 1196, "status": "ok", "timestamp": 1646400760853, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "HPcwghzKIBbR", "outputId": "29ccc3b9-af5f-4270-bedf-4a17524b50e4"}, "outputs": [], "source": ["# function to plot an image in a subplot\n", "def subplot_image(image, label, nrows=1, ncols=1, iplot=0, label2='', label2_color='r'):\n", "    plt.subplot(nrows, ncols, iplot + 1)\n", "    plt.imshow(image.squeeze(), cmap=plt.cm.binary)\n", "    plt.xlabel(label, c='k', fontsize=8)\n", "    plt.title(label2, c=label2_color, fontsize=8, y=-0.33)\n", "    plt.xticks([])\n", "    plt.yticks([])\n", "    \n", "# ramdomly plot some images and their labels\n", "nrows = 4\n", "ncols = 8\n", "plt.figure(dpi=100, figsize=(ncols * 2, nrows * 2.2))\n", "for iplot, idata in enumerate(np.random.choice(len(y_train), nrows * ncols)):\n", "    label = \"%d: %s\" % (y_train[idata], string_labels[y_train[idata]])\n", "    subplot_image(x_train[idata], label, nrows, ncols, iplot)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"id": "TlxLCYDqIBbS"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "EHMycuFuIBbT"}, "source": ["# 2. Build the network\n", "\n", "The task is to build and train a CNN to solve this binary classification problem. \n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "model = Sequential()\n", "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', padding='same',\n", "                 input_shape=(32, 32, 1)))\n", "model.add(MaxPool2D(pool_size=(2, 2)))\n", "model.add(BatchNormalization())\n", "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'))\n", "model.add(MaxPool2D(pool_size=(2, 2)))\n", "model.add(BatchNormalization())\n", "model.add(Flatten())\n", "model.add(Dense(1, activation='sigmoid'))\n", "\n", "# print summary\n", "model.summary()\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 503, "status": "ok", "timestamp": 1646400761541, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "h3HPHWpPIBbU", "outputId": "6bd97955-0abe-4357-9459-4db13b02df58"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "1DURdhAVIBbU"}, "source": ["###  Compile the model\n", "\n", "We can add the following metrics to see how the network performs for the two classes:\n", "\n", "* `TruePositives`: number of right predictions for paramagnetic\n", "* `FalsePositives`: number of wrong predictions for paramagnetic\n", "* `TrueNegatives`: number of right predictions for ferromagnetic\n", "* `FalseNegatives`: number of wrong predictions for ferromagnetic\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "model.compile(optimizer='adam', loss='binary_crossentropy', \n", "              metrics= ['accuracy',\n", "                        keras.metrics.TruePositives(name='true_positives'),\n", "                        keras.metrics.FalsePositives(name='false_positives'),\n", "                        keras.metrics.TrueNegatives(name='true_negatives'),\n", "                        keras.metrics.FalseNegatives(name='false_negatives')])\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "3eV6d0JrIBbV"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "-a1YscORIBbV"}, "source": ["### Train the model\n", "\n", "Using the suggested architecture, we can achieve an accuracy greater than 97% with 2 epochs. \n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "stopper=EarlyStopping( monitor =\"val_loss\", min_delta=0.0,verbose=1,\n", "                      mode=\"min\",\n", "                      restore_best_weights=True,patience=2)\n", "\n", "training_history = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n", "                             epochs=10, batch_size=64,callbacks=[stopper])\n", "\n", "# print final values of metrics for validation data\n", "print('Right for Paramagnetic: %d' % training_history.history['val_true_positives'][-1])\n", "print('Wrong for Paramagnetic: %d' % training_history.history['val_false_positives'][-1])\n", "print('Right for Ferromagnetic: %d' % training_history.history['val_true_negatives'][-1])\n", "print('Wrong for Ferromagnetic: %d' % training_history.history['val_false_negatives'][-1])\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 76395, "status": "ok", "timestamp": 1646400915611, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "CutXmWrrIBbV", "outputId": "a7f0bd30-cc61-4ca5-c302-e98dc1a781a1"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "WIegCrM3IBbX"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "auKT1kURIBbY"}, "source": ["# 3. Analyse results "]}, {"cell_type": "markdown", "metadata": {"id": "IKCZM6vWIBbY"}, "source": ["### Plot training history\n", "\n", "For convenience, we define a function to plot a training history:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "1pm9Hg3eIBbY"}, "outputs": [], "source": ["# a function to plot training history\n", "def plot_history(training_history):\n", "    # plot accuracy\n", "    plt.figure(dpi=100, figsize=(12, 4))\n", "    plt.subplot(1, 2, 1)\n", "    plt.plot(training_history.history[acc_str], label='Accuracy on training data')\n", "    plt.plot(training_history.history['val_' + acc_str], label='Accuracy on test data')\n", "    plt.legend()\n", "    plt.title(\"Accuracy\")\n", "\n", "    # plot loss\n", "    plt.subplot(1, 2, 2)\n", "    plt.plot(training_history.history['loss'], label='Loss on training data')\n", "    plt.plot(training_history.history['val_loss'], label='Loss on test data')\n", "    plt.legend()\n", "    plt.title(\"Loss\")\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {"id": "gaPANfPXIBbZ"}, "source": ["**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# plot training history\n", "plot_history(training_history)\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 385}, "executionInfo": {"elapsed": 7782, "status": "ok", "timestamp": 1646400923388, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "Jemv4st_IBbZ", "outputId": "1d8ff878-7e48-4d81-aa0f-1f9ac9214f6a"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "sSdr9yxyIBbZ"}, "source": ["# 4. Exercises\n", "\n", "* Change some hyperparameters in `model.compile()` and `model.fit()` to see their effects (see reference of [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)); \n", "* Change the architeture and activation functions of neural networks to improve the accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "8P1KWTI-IBbZ"}, "outputs": [], "source": []}], "metadata": {"colab": {"collapsed_sections": [], "name": "Physics_ferromagnetic and paramagnetic classification_solution.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 1}