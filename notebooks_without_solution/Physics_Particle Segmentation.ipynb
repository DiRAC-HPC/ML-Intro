{"cells": [{"cell_type": "markdown", "metadata": {"id": "2NgnW6WhYtv3"}, "source": ["# 0. Particle segmentation\n", "\n", "In this notebook, we attempt to train neural networks for particle segmentation\n", "\n", "We use a slimmed down dataset of a public dataset from the [Deep Learn Physics Challenge](http://deeplearnphysics.org/DataChallenge/). The dataset is a set of images of five types particles (electron, gamma ray, muon, charged pion, and proton) projected in the xy-plane. For semantic segmentation, the images are labelled with three classes: background, EM-shower particles, and track particles (i.e. not EM-shower). \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 6727, "status": "ok", "timestamp": 1646405043520, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "eocFdzxBYtv6", "outputId": "a2bf13ac-f15a-40fa-b682-4998ff46c667"}, "outputs": [], "source": ["# tensorflow\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, Dense, Flatten, Dropout, Activation, BatchNormalization, SeparableConv2D, UpSampling2D\n", "\n", "\n", "# check version\n", "print('Using TensorFlow v%s' % tf.__version__)\n", "acc_str = 'accuracy' if tf.__version__[:2] == '2.' else 'acc'\n", "\n", "# helpers\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import h5py\n", "from sklearn.model_selection import train_test_split\n", "from os.path import join\n", "\n", "\n", "# need some certainty in data processing\n", "np.random.seed(1234)\n", "tf.random.set_seed(1234)\n", "\n", "data_path = 'data'"]}, {"cell_type": "markdown", "metadata": {"id": "Fyi2fYNCYtv8"}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "metadata": {"executionInfo": {"elapsed": 16300, "status": "ok", "timestamp": 1646405059806, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "2GKN4ATfYtv9"}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 14059, "status": "ok", "timestamp": 1646405073860, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "_s8F24U2Ytv9", "outputId": "57113bea-df56-48a0-9108-2b652e09a744"}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "metadata": {"id": "1QHSeL6JYtv-"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "aXaWrt-sYtv_"}, "source": ["# 1. Load the dataset\n", "\n", "### Read raw data\n", "\n", "Our data are stored in the hdf files physics/phy_seg_train_img.h5, physics/phy_seg_train_lab.h5 and physics/phy_seg_test_img.h5, physics/phy_seg_test_lab.h5 containing 2,000 images and 2,000 labels, respectively.  \n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# load dataset\n", "with h5py.File(join(data_path, 'Physics/phy_seg_train_img.h5'), 'r') as F:\n", "    x_train = np.expand_dims(np.array(F['images']), axis = -1)\n", "    x_train = x_train.astype(np.float32)\n", "    x_train = x_train/255.\n", "\n", "with h5py.File(join(data_path, 'Physics/phy_seg_train_lab.h5'), 'r') as F:\n", "    y_train = np.expand_dims(np.array(F['labels']), axis = -1)\n", "    y_train = y_train.astype(np.float32)\n", "\n", "with h5py.File(join(data_path, 'Physics/phy_seg_test_img.h5'), 'r') as F:\n", "    x_test = np.expand_dims(np.array(F['images']), axis = -1)\n", "    x_test = x_test.astype(np.float32)\n", "    x_test = x_test/255.\n", "\n", "with h5py.File(join(data_path, 'Physics/phy_seg_test_lab.h5'), 'r') as F:\n", "    y_test = np.expand_dims(np.array(F['labels']), axis = -1)\n", "    y_test = y_test.astype(np.float32)\n", "    \n", "# print info\n", "print(\"Number of training data: %d\" % len(y_train))\n", "print(\"Number of test data: %d\" % len(y_test))\n", "print(\"Image pixels: %s\" % str(x_train[0, :, :, 0].shape))\n", "print(\"Number of channels: %s\" % str(x_train.shape[-1]))\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 4156, "status": "ok", "timestamp": 1646405078010, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "-BXi-Xa2Ytv_", "outputId": "5a8593a1-e9b8-4fef-9c63-d79df33d6280"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 264}, "executionInfo": {"elapsed": 1469, "status": "ok", "timestamp": 1646405093298, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "k-rbjtVsYtwB", "outputId": "1a34ae7c-6f65-4f88-925a-60886bf635c2"}, "outputs": [], "source": ["fig, axes = plt.subplots(2, 5, figsize = (11, 4))\n", "for i in range(5):\n", "    rnd_idx = np.random.choice(len(x_train), 1)[0]\n", "    axes[0][i].imshow(x_train[rnd_idx].reshape(256, 256))\n", "    axes[0][i].set_title('image')\n", "    axes[0][i].axis('off')\n", "    axes[1][i].imshow(y_train[rnd_idx].reshape(256, 256))\n", "    axes[1][i].set_title('label')\n", "    axes[1][i].axis('off')\n", "    \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "ulTtDFnzYtwC"}, "source": ["# 2. Build the network\n", "\n", "We use U-Net Xception-style model following [Keras official document](https://keras.io/examples/vision/oxford_pets_image_segmentation/). \n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "inputs = tf.keras.Input(shape=(256, 256, 1))\n", "\n", "### [First half of the network: downsampling inputs] ###\n", "\n", "# Entry block\n", "x = Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n", "x = BatchNormalization()(x)\n", "x = Activation(\"relu\")(x)\n", "\n", "previous_block_activation = x  # Set aside residual\n", "\n", "# Blocks 1, 2, 3 are identical apart from the feature depth.\n", "for filters in [64, 128, 256]:\n", "    x = Activation(\"relu\")(x)\n", "    x = SeparableConv2D(filters, 3, padding=\"same\")(x)\n", "    x = BatchNormalization()(x)\n", "\n", "    x = Activation(\"relu\")(x)\n", "    x = SeparableConv2D(filters, 3, padding=\"same\")(x)\n", "    x = BatchNormalization()(x)\n", "\n", "    x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n", "\n", "    # Project residual\n", "    residual = Conv2D(filters, 1, strides=2, padding=\"same\")(\n", "        previous_block_activation\n", "    )\n", "    x = keras.layers.add([x, residual])  # Add back residual\n", "    previous_block_activation = x  # Set aside next residual\n", "\n", "    ### [Second half of the network: upsampling inputs] ###\n", "\n", "for filters in [256, 128, 64, 32]:\n", "    x = Activation(\"relu\")(x)\n", "    x = Conv2DTranspose(filters, 3, padding=\"same\")(x)\n", "    x = BatchNormalization()(x)\n", "\n", "    x = Activation(\"relu\")(x)\n", "    x = Conv2DTranspose(filters, 3, padding=\"same\")(x)\n", "    x = BatchNormalization()(x)\n", "\n", "    x = UpSampling2D(2)(x)\n", "\n", "    # Project residual\n", "    residual = UpSampling2D(2)(previous_block_activation)\n", "    residual = Conv2D(filters, 1, padding=\"same\")(residual)\n", "    x = keras.layers.add([x, residual])  # Add back residual\n", "    previous_block_activation = x  # Set aside next residual\n", "\n", "# Add a per-pixel classification layer\n", "outputs = Conv2D(3, 3, activation=\"softmax\", padding=\"same\")(x)\n", "\n", "# Define the model\n", "model = tf.keras.Model(inputs, outputs)\n", "\n", "model.summary()\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 5350, "status": "ok", "timestamp": 1646405102590, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "lrFRt357YtwC", "outputId": "45c74c06-a085-49d5-efec-9fde112c59ec"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "z5XNTqAGYtwD"}, "source": ["### Compile and train the model\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# optimizer, loss, metrics\n", "model.compile(optimizer='adam',\n", "              loss=tf.keras.losses.SparseCategoricalCrossentropy())\n", "\n", "# train the model\n", "training_history = model.fit(x_train, y_train, epochs=10, batch_size=32)\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 689075, "status": "ok", "timestamp": 1646405791660, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "5FatwCgQYtwF", "outputId": "26d58404-3424-4846-92bf-3cc7f0e5d53e"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "N_5Xn7HmYtwF"}, "source": ["# 3. Analyse results "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Check training history\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "plt.figure\n", "plt.plot(training_history.history['loss'], label='Loss on training data')\n", "plt.legend()\n", "plt.title(\"Loss\")\n", "plt.show()\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 281}, "executionInfo": {"elapsed": 476, "status": "ok", "timestamp": 1646405792128, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "1A4fIFm1YtwF", "outputId": "cb4c8211-706c-46e5-d630-7b89c9027956"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "qsZFZNASYtwH"}, "source": ["### Make predictions"]}, {"cell_type": "code", "execution_count": null, "metadata": {"executionInfo": {"elapsed": 23605, "status": "ok", "timestamp": 1646405815719, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "sVIcOCJ_YtwI"}, "outputs": [], "source": ["# use a batch of test images to predict\n", "batch = x_test[:32]\n", "pred_labels = model.predict(batch).argmax(axis=-1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 575}, "executionInfo": {"elapsed": 1098, "status": "ok", "timestamp": 1646405816810, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "BU8ugtqbYtwI", "outputId": "5bb0555e-078f-480a-cdf8-d25c02b3c01a"}, "outputs": [], "source": ["fig, axes = plt.subplots(3, 5, figsize = (15, 10))\n", "for i in range(5):\n", "    rnd_idx = np.random.choice(len(batch), 1)[0]\n", "    axes[0][i].imshow(x_test[rnd_idx].reshape(256, 256))\n", "    axes[0][i].set_title('image')\n", "    axes[0][i].axis('off')\n", "    axes[1][i].imshow(y_test[rnd_idx].reshape(256, 256))\n", "    axes[1][i].set_title('label')\n", "    axes[1][i].axis('off')\n", "    axes[2][i].imshow(pred_labels[rnd_idx].reshape(256, 256))\n", "    axes[2][i].set_title('label')\n", "    axes[2][i].axis('off')     "]}, {"cell_type": "markdown", "metadata": {"id": "-x9VhtcEYtwJ"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "MpSIkznDYtwJ"}, "source": ["# 4.Exercises\n", "\n", "Think segmentation as a classification task on pixel level. In this case, the number of background is much greater than the number of EM-shower particles and track particles, which causes label imbalance. \n", "\n", "* Add more convolutional layers\n", "* Weight EM-shower particles and track particles labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "ZpuCbdFQYtwJ"}, "outputs": [], "source": []}], "metadata": {"accelerator": "GPU", "colab": {"collapsed_sections": [], "name": "Physics_Particle segmentation_solution.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 1}