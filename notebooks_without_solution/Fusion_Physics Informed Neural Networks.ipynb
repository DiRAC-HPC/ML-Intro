{"cells": [{"cell_type": "markdown", "id": "f592f9a6", "metadata": {}, "source": ["# 0. Solving 2D Wave Equation \n", "Training Neural Network to converge towards a well-defined solution of a PDE by way of minimising for the residuals across the spatio-temporal domain. Initial and Boundary conditions are met by introducing them into the loss function along with the PDE residuals. \n", "\n", "Numerical Method - Spectral Solver using FFT. <br>\n", "Code taken from [this tutorial.](http://people.bu.edu/andasari/courses/numericalpython/Week12Lecture21/Spectral_wave2.py) <br>\n", "\n", "Equation: \n", "```\n", "u_tt = u_xx + u_yy on [-1,1] x [-1,1] \n", "```\n", "\n", "Dirichlet Boundary Conditions : \n", "```\n", "u=0\n", "```\n", "\n", "Initial Distribution :\n", "```\n", " u(x,y,t=0) = exp(-40(x-4)^2 + y^2)\n", " ```\n", "\n", "Initial Velocity Condition : \n", "```\n", "u_t(x,y,t=0) = 0\n", "```\n"]}, {"cell_type": "code", "execution_count": null, "id": "b35a9fe3", "metadata": {}, "outputs": [], "source": ["# tensorflow\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\n", "\n", "# check version\n", "print('Using TensorFlow v%s' % tf.__version__)\n", "acc_str = 'accuracy' if tf.__version__[:2] == '2.' else 'acc'\n", "\n", "# helpers\n", "import numpy as np\n", "from scipy import interpolate\n", "import matplotlib.pyplot as plt\n", "from mpl_toolkits.mplot3d import Axes3D\n", "from matplotlib import cm\n", "import h5py\n", "from os.path import join\n", "\n", "# need some certainty in data processing\n", "np.random.seed(1234)\n", "tf.random.set_seed(1234)\n", "\n", "data_path = 'data'"]}, {"cell_type": "markdown", "id": "b08cb9a3", "metadata": {}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "id": "87b12c9c", "metadata": {}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "id": "1c819db9", "metadata": {}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "id": "3bc178f5", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "ed6ecb54", "metadata": {}, "source": ["# 1. Load the dataset\n", "\n", "### Load conditions and the numerical solution \n", "\n", "The numerical solution was computed by solving the Wave Equation using a spectral solver. The solution will not form the training data but will be used for comparing against the output of the neural network. "]}, {"cell_type": "code", "execution_count": null, "id": "46dab55e", "metadata": {}, "outputs": [], "source": ["with h5py.File(join(data_path, 'Fusion/pde_2d_wave.h5'), 'r') as F:\n", "    x = np.array(F['x'], dtype='float32')\n", "    y = np.array(F['y'], dtype='float32')\n", "    t = np.array(F['t'], dtype='float32')\n", "    lb = np.array(F['lower_range'], dtype='float32')   # Lower Bounds of the domain\n", "    ub = np.array(F['upper_range'], dtype='float32')   # Upper Bounds of the domain\n", "    u_sol = np.array(F['U_sol'], dtype='float32')      # Solution of the 2D Wave Equation\n", "    X_i = np.array(F['X_i'], dtype='float32')          # Data for Initial Input\n", "    U_i = np.array(F['u_i'], dtype='float32')          # Data for Initial Input\n", "    X_b = np.array(F['X_b'], dtype='float32')          # Data for Boundary Input\n", "    X_f = np.array(F['X_f'], dtype='float32')          # Data for Domain Input\n", "\n"]}, {"cell_type": "markdown", "id": "e1498157", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "9e91343c", "metadata": {}, "source": ["# 2. Build the network"]}, {"cell_type": "markdown", "id": "1c8d1702", "metadata": {}, "source": ["We will build a neural network with 5 hidden layers.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "in_features = 3\n", "num_layers = 5\n", "out_features = 1\n", "num_neurons = 100\n", "\n", "\n", "npde_net = Sequential()\n", "npde_net.add(Dense(100, activation='tanh', input_shape=(in_features,)))\n", "for _ in range(num_layers - 1):\n", "     npde_net.add(Dense(num_neurons, activation='tanh'))\n", "\n", "npde_net.add(Dense(out_features))\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "03f69c07", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "91874be7", "metadata": {}, "outputs": [], "source": ["optimizer = tf.keras.optimizers.Adam()\n", "\n", "def train_step(X_i, Y_i, X_b, X_f):\n", "    with tf.GradientTape() as tape:\n", "        # recon loss\n", "        recon_loss = npde_net(X_i) - Y_i\n", "\n", "        # initial_cond_loss\n", "        xi_ = tf.Variable(X_i[:, 0:1])\n", "        yi_ = tf.Variable(X_i[:, 1:2])\n", "        ti_ = tf.Variable(X_i[:, 2:3])\n", "        with tf.GradientTape() as ti:\n", "            ui = npde_net(tf.concat([xi_,yi_,ti_],1))\n", "\n", "        ui_t = ti.gradient(ui, ti_)\n", "        initial_cond_loss = ui_t - 0\n", "        \n", "        # boundary_loss\n", "        ub = npde_net(X_b)\n", "        bc_loss = ub - 0 \n", "\n", "        # domain_loss\n", "        xf_ = tf.Variable(X_f[:, 0:1])\n", "        yf_ = tf.Variable(X_f[:, 1:2])\n", "        tf_ = tf.Variable(X_f[:, 2:3])\n", "        \n", "        # build graph with GradientTape\n", "        with tf.GradientTape() as tapex, tf.GradientTape() as tapey, tf.GradientTape() as tapet:\n", "            with tf.GradientTape() as tape1:\n", "                uf = npde_net(tf.concat([xf_,yf_,tf_],1))\n", "        \n", "            deriv1 = tape1.gradient(uf, {'x': xf_, 'y': yf_, 't':tf_})\n", "        uf_xx = tapex.gradient(deriv1['x'], xf_) \n", "        uf_yy = tapey.gradient(deriv1['y'], yf_) \n", "        uf_tt = tapet.gradient(deriv1['t'], tf_)   \n", "\n", "        pde_loss = uf_tt - (uf_xx + uf_yy)\n", "\n", "        initial_loss = tf.reduce_mean(tf.math.square(recon_loss)) + tf.reduce_mean(tf.math.square(initial_cond_loss))\n", "        boundary_loss = tf.reduce_mean(tf.math.square(bc_loss))\n", "        domain_loss = tf.reduce_mean(tf.math.square(pde_loss))\n", "\n", "        loss = initial_loss + boundary_loss + domain_loss \n", "\n", "    grads = tape.gradient(loss, npde_net.trainable_variables)\n", "    optimizer.apply_gradients(zip(grads, npde_net.trainable_variables))\n", "    return loss"]}, {"cell_type": "code", "execution_count": null, "id": "cfab40dc", "metadata": {}, "outputs": [], "source": ["interations = 5000\n", "for i in range(interations):\n", "    loss = train_step(X_i, U_i, X_b, X_f)\n", "    if i % 100 == 0:\n", "        print('epoch {}/{} ({:.2f}%): loss: {}'.format(i,interations, 100*(i/interations), loss.numpy()))\n", "print('Final loss: {}'.format(loss.numpy()))"]}, {"cell_type": "markdown", "id": "9dd4c2c6", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "2a5f03c7", "metadata": {}, "source": ["# 3. Analyse results "]}, {"cell_type": "markdown", "id": "268f88f3", "metadata": {}, "source": ["### Predict u from pairs of x, y, and t"]}, {"cell_type": "code", "execution_count": null, "id": "bc9db866", "metadata": {}, "outputs": [], "source": ["X, Y = np.meshgrid(x, y)\n", "XY_star = np.hstack((X.flatten()[:,None], Y.flatten()[:,None]))\n", "T_star = np.expand_dims(np.repeat(t, len(XY_star)), 1)\n", "X_star_tiled = np.tile(XY_star, (len(t), 1))\n", "\n", "X_star = np.hstack((X_star_tiled, T_star))\n", "u_pred = npde_net(X_star).numpy()\n", "u_pred = u_pred.reshape(u_sol.shape)"]}, {"cell_type": "markdown", "id": "8ff95791", "metadata": {}, "source": ["### Compare solution by the neural network against the Numerical solution. "]}, {"cell_type": "code", "execution_count": null, "id": "43d54750", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=plt.figaspect(0.5))\n", "ax = fig.add_subplot(2,3,1)\n", "ax.imshow(u_sol[0])\n", "ax.title.set_text('Initial')\n", "ax.set_ylabel('Solution')\n", "\n", "ax = fig.add_subplot(2,3,2)\n", "ax.imshow(u_sol[int(len(u_sol)/2)])\n", "ax.title.set_text('Middle')\n", "\n", "ax = fig.add_subplot(2,3,3)\n", "ax.imshow(u_sol[-1])\n", "ax.title.set_text('Final')\n", "\n", "\n", "fig = plt.figure(figsize=plt.figaspect(0.5))\n", "ax = fig.add_subplot(2,3,1)\n", "ax.imshow(u_pred[0])\n", "ax.title.set_text('Initial')\n", "ax.set_ylabel('Prediction')\n", "\n", "ax = fig.add_subplot(2,3,2)\n", "ax.imshow(u_pred[int(len(u_sol)/2)])\n", "ax.title.set_text('Middle')\n", "\n", "ax = fig.add_subplot(2,3,3)\n", "ax.imshow(u_pred[-1])\n", "ax.title.set_text('Final')"]}, {"cell_type": "code", "execution_count": null, "id": "09f41df4", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "1c34bec1", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}