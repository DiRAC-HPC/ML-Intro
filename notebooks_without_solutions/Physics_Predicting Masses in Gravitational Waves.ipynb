{"cells": [{"cell_type": "markdown", "id": "de140b96", "metadata": {"id": "de140b96"}, "source": ["# 0. Gravitational waves regression\n", "\n", "In this notebook, we attempt to build a neural network to estimate two masses in gravitational waves. \n", "\n", "Gravitational waves are disturbances in the curvature of spacetime, generated by accelerated masses, that propagate as waves outward from their source at the speed of light. The gravitational waves used in this tutorial are generated with two masses $m_1$ and $m_2$. The detial description of the data are published in [LALSuite IMRPhenomD generator](https://arxiv.org/pdf/1508.07250.pdf). \n", "\n", "The aim of this work is to estimate two masses $m_1$ and $m_2$ using 1d convolutional and dense layers. \n"]}, {"cell_type": "code", "execution_count": null, "id": "8348369b", "metadata": {"id": "8348369b"}, "outputs": [], "source": ["from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Multiply, Add, Flatten, Dropout\n", "from tensorflow.keras.models import Model\n", "from tensorflow.keras import Sequential\n", "from tensorflow.keras.callbacks import EarlyStopping\n", "import tensorflow as tf\n", "\n", "# sklearn\n", "from sklearn import metrics\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n", "from sklearn.ensemble import GradientBoostingRegressor\n", "import sklearn.datasets\n", "from sklearn.preprocessing import StandardScaler\n", "\n", "# helpers\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "from os.path import join\n", "\n", "data_path = 'data'"]}, {"cell_type": "markdown", "id": "5141704e", "metadata": {"id": "5141704e"}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "id": "8a7f8326", "metadata": {"id": "8a7f8326"}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "id": "e949aefc", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 17532, "status": "ok", "timestamp": 1646401520930, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "e949aefc", "outputId": "8e7ba6b9-1e2b-4496-9e60-a2961754c52c"}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "id": "b93ddc1f", "metadata": {"id": "b93ddc1f"}, "source": ["---"]}, {"cell_type": "markdown", "id": "a5da08b0", "metadata": {"id": "a5da08b0"}, "source": ["# 1. Load the dataset\n", "\n", "### Read raw data\n", "\n", "The data is stored in 'Physics/gravitational_wave_dataset.npz', containing 2,000 signals: 1,000 examples of signals and 1,000 examples of pure noise. The signals are 1 second long with a sample rate of 8196. We will use 1,000 examples of signals for a regression task.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "grav_wave = np.load(join(data_path, 'Physics/gravitational_wave_dataset.npy'), allow_pickle=True)\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "2bbb9e45", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "e2430fae", "metadata": {"id": "e2430fae"}, "outputs": [], "source": ["def prepare_datset(X, target = 'regression'):\n", "    if target == 'regression':\n", "        x = np.expand_dims(np.sum(np.stack(X[:1000, 2]), axis = -1), axis = -1).astype(np.float32)\n", "        y = np.stack([[w[0] for w in  grav_wave[j, [3, 4]]] for j in np.arange(1000)])\n", "        y = y.reshape(len(x), 2).astype(np.float32)\n", "        \n", "    elif target == 'classification':\n", "        x = np.expand_dims(np.sum(np.stack(X[:, 1]), axis = -1), axis = -1)\n", "        y = X[:, 0].astype(np.int)\n", "        \n", "    return x, y"]}, {"cell_type": "markdown", "id": "bf3137e6", "metadata": {}, "source": ["Prepare a dataset for a regression task using the prepare_dataset function and split it using the train_test_split funtion\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "x, y = prepare_datset(grav_wave, target = 'regression')\n", "\n", "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n", "\n", "print('x_train shape: ', x_train.shape)\n", "print('y_train shape: ', y_train.shape)\n", "print('x_test shape: ', x_test.shape)\n", "print('y_test shape: ', y_test.shape)    \n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "e8796b36", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 4347, "status": "ok", "timestamp": 1646401552826, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "e8796b36", "outputId": "11395c4b-ef39-4088-8f21-b0512c51a776"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "41d0fe3a", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 444}, "executionInfo": {"elapsed": 1828, "status": "ok", "timestamp": 1646401554647, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "41d0fe3a", "outputId": "8f30b082-db16-467e-ccd4-f9429edfc775"}, "outputs": [], "source": ["fig, axes = plt.subplots(2, 4, figsize = (16, 7))\n", "\n", "rnd_idx = np.random.choice(len(x_train), 8)\n", "for i in range(2):\n", "    for j in range(4):\n", "        axes[i][j].plot(x_train[rnd_idx[2*i+j]])\n", "        axes[i][j].set_title('m1: {:.2f} and m2: {:.2f}'.format(y_train[rnd_idx[2*i+j]][0], y_train[rnd_idx[2*i+j]][1]))"]}, {"cell_type": "markdown", "id": "e25b53ef", "metadata": {"id": "e25b53ef"}, "source": ["---"]}, {"cell_type": "markdown", "id": "8bc9fd09", "metadata": {"id": "8bc9fd09"}, "source": ["# 2. Build the network\n", "\n", "We will build a linear regression using sklearn and a 1D-convolutional neural network to compare their results.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# fit linear regression model\n", "model = LinearRegression().fit(x_train.reshape(-1, 8192), y_train)\n", "# make predictions\n", "y_train_pred = model.predict(x_train.reshape(-1, 8192))\n", "y_test_pred = model.predict(x_test.reshape(-1, 8192))\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "id": "51f38388", "metadata": {"id": "51f38388"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "01145a61", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 13, "status": "ok", "timestamp": 1646401555823, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "01145a61", "outputId": "cfb44326-fb64-473a-8a18-3d0a37cbdb5f"}, "outputs": [], "source": ["# compute some fitting error\n", "print('MSE on the train set = %f ' % metrics.mean_squared_error(y_train, y_train_pred))\n", "print('MAE on the train set = %f ' % metrics.mean_absolute_error(y_train, y_train_pred))\n", "print('MSE on the test set = %f ' % metrics.mean_squared_error(y_test, y_test_pred))\n", "print('MAE on the test set = %f ' % metrics.mean_absolute_error(y_test, y_test_pred))"]}, {"cell_type": "code", "execution_count": null, "id": "9e82dde6", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 297}, "executionInfo": {"elapsed": 1173, "status": "ok", "timestamp": 1646401560515, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "9e82dde6", "outputId": "e0b52720-bfa2-4447-a120-bda3ba6846e6"}, "outputs": [], "source": ["fig, axes = plt.subplots(1, 4, figsize = (17, 4))\n", "\n", "axes[0].scatter(y_train[:, 0], y_train_pred[:, 0])\n", "axes[0].set_title('results on the train set')\n", "axes[0].set_xlabel('True M1')\n", "axes[0].set_ylabel('Predicted M1')\n", "\n", "axes[1].scatter(y_test[:, 0], y_test_pred[:, 0])\n", "axes[1].set_title('results on the train set')\n", "axes[1].set_xlabel('True M1')\n", "axes[1].set_ylabel('Predicted M1')\n", "\n", "axes[2].scatter(y_train[:, 1], y_train_pred[:, 1])\n", "axes[2].set_title('results on the train set')\n", "axes[2].set_xlabel('True M2')\n", "axes[2].set_ylabel('Predicted M2')\n", "\n", "axes[3].scatter(y_test[:, 1], y_test_pred[:, 1])\n", "axes[3].set_title('results on the train set')\n", "axes[3].set_xlabel('True M2')\n", "axes[3].set_ylabel('Predicted M2')\n", "\n", "fig.tight_layout()"]}, {"cell_type": "markdown", "id": "455f90c2", "metadata": {}, "source": ["### Use 1D-convolutional layers to build a neural network\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "model = Sequential()\n", "model.add(Input(shape=(x_train.shape[1],1,)))\n", "\n", "model.add(Conv1D(filters=16, kernel_size=7, strides = 2, activation='relu'))\n", "model.add(MaxPooling1D(2))\n", "model.add(Conv1D(filters=32, kernel_size=7, strides = 2, activation='relu'))\n", "model.add(MaxPooling1D(2))\n", "model.add(Flatten())\n", "model.add(Dense(1024, activation=\"relu\"))\n", "model.add(Dropout(0.2))\n", "model.add(Dense(2))        \n", "\n", "opt = tf.keras.optimizers.Adam(0.01)\n", "model.compile(loss=\"mse\", optimizer=opt)\n", "\n", "\n", "\n", "stopper=EarlyStopping(monitor =\"val_loss\", min_delta=0.0,verbose=1,\n", "                      mode=\"min\", restore_best_weights=True,patience=5)\n", "history = model.fit(x_train, y_train, epochs=99, batch_size=64, \n", "                             validation_split = 0.2 ,callbacks=[stopper])\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "98c02d3e", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 150819, "status": "ok", "timestamp": 1646401711329, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "98c02d3e", "outputId": "ff07783d-708a-437e-a48f-f192736e8743"}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "c2b2d561", "metadata": {"id": "c2b2d561"}, "source": ["# 3. Analyse results "]}, {"cell_type": "markdown", "id": "55b5ce5d", "metadata": {"id": "55b5ce5d"}, "source": ["### prediction\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "y_train_pred = model.predict(x_train)\n", "y_test_pred = model.predict(x_test)\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "69b78a48", "metadata": {"id": "69b78a48"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "6ff6a1cc", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 11, "status": "ok", "timestamp": 1646401713678, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "6ff6a1cc", "outputId": "3a17cd02-a4b0-43c6-da09-b6c7a6f1d018"}, "outputs": [], "source": ["# compute some fitting error\n", "print('MSE on the train set = %f ' % metrics.mean_squared_error(y_train, y_train_pred))\n", "print('MAE on the train set = %f ' % metrics.mean_absolute_error(y_train, y_train_pred))\n", "print('MSE on the test set = %f ' % metrics.mean_squared_error(y_test, y_test_pred))\n", "print('MAE on the test set = %f ' % metrics.mean_absolute_error(y_test, y_test_pred))"]}, {"cell_type": "code", "execution_count": null, "id": "813af6cf", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 621}, "executionInfo": {"elapsed": 925, "status": "ok", "timestamp": 1646401714598, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "813af6cf", "outputId": "ef51df13-00b1-4f2a-f62f-937a63ac1c04"}, "outputs": [], "source": ["fig, axes = plt.subplots(nrows=2, ncols=2, figsize = (10, 10))\n", "\n", "axes[0][0].scatter(y_train[:, 0], y_train_pred[:, 0])\n", "axes[0][0].plot([y_train[:, 0].min(), y_train[:, 0].max()], [y_train[:, 0].min(), y_train[:, 0].max()],'r')\n", "axes[0][0].set_title('results on the train set')\n", "axes[0][0].set_xlabel('True M1')\n", "axes[0][0].set_ylabel('Predicted M1')\n", "\n", "\n", "axes[0][1].scatter(y_test[:, 0], y_test_pred[:, 0])\n", "axes[0][1].plot([y_test[:, 0].min(), y_test[:, 0].max()], [y_test[:, 0].min(), y_test[:, 0].max()],'r')\n", "axes[0][1].set_title('results on the train set')\n", "axes[0][1].set_xlabel('True M1')\n", "axes[0][1].set_ylabel('Predicted M1')\n", "\n", "\n", "axes[1][0].scatter(y_train[:, 1], y_train_pred[:, 1])\n", "axes[1][0].plot([y_train[:, 1].min(), y_train[:, 1].max()], [y_train[:, 1].min(), y_train[:, 1].max()],'r')\n", "axes[1][0].set_title('results on the train set')\n", "axes[1][0].set_xlabel('True M2')\n", "axes[1][0].set_ylabel('Predicted M2')\n", "\n", "\n", "axes[1][1].scatter(y_test[:, 1], y_test_pred[:, 1])\n", "axes[1][1].plot([y_test[:, 1].min(), y_test[:, 1].max()], [y_test[:, 1].min(), y_test[:, 1].max()],'r')\n", "axes[1][1].set_title('results on the train set')\n", "axes[1][1].set_xlabel('True M2')\n", "axes[1][1].set_ylabel('Predicted M2')\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "2e3b8f5d", "metadata": {"id": "2e3b8f5d"}, "source": ["---"]}, {"cell_type": "markdown", "id": "894a5957", "metadata": {"id": "894a5957"}, "source": ["# 4. Exercises\n", "\n", "* Change some hyperparameters in `model.compile()` and `model.fit()` to see their effects (see reference of [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)); \n", "* Change the architeture and activation functions of neural networks to improve the performance on the test set"]}, {"cell_type": "code", "execution_count": null, "id": "eb89b1b6", "metadata": {"id": "eb89b1b6"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "6039ac53", "metadata": {"id": "6039ac53"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "5d25755a", "metadata": {"id": "5d25755a"}, "outputs": [], "source": []}], "metadata": {"colab": {"collapsed_sections": [], "name": "Physics_LIGOWAVE 1D regression_solution.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}