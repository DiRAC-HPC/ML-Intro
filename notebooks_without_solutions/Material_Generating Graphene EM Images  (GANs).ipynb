{"cells": [{"cell_type": "markdown", "metadata": {"id": "IL9SW6kO1Pea"}, "source": ["# 0. Generating Graphene EM Images using Generative Adversarial Networks (GANs).\n", "\n", "In this notebook, we attempt to build Generative Adversarial Networks (GANs) to generate new samples plausibly drawn from the training dataset.\n", "\n", "Inelastic neutron scattering (INS) can be used to infer information about the forces present in a material. Neutrons scatter off a sample, exchanging energy with certain fundamental vibrational modes of the sample. These vibraional modes include phonons (interatomic boding forces) and magnons (spin coupling between magnetic nuclei). \n", "\n", "[Johnstone et al. (2012)](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.109.237202) have simulated magnon spectra from a double perovskite systems, where INS was used to distinguish between two possible magnetic Hamiltonians of the system. For this practical, we have simulated datasets for each of the possible Hamiltonians. We are going to train a CNN to classify the system correctly.\n", "\n", "\n", "The aim of this work is to generate more diverse data that are plausibly drawn from the training dataset using GANs. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 5205, "status": "ok", "timestamp": 1646392454005, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "fhRLCYd81Peb", "outputId": "2fe085c5-d8f8-4f5e-a732-55ce5e331a7d"}, "outputs": [], "source": ["# tensorflow\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras.models import Sequential\n", "import tensorflow.keras.layers as layers\n", "\n", "# check version\n", "print('Using TensorFlow v%s' % tf.__version__)\n", "acc_str = 'accuracy' if tf.__version__[:2] == '2.' else 'acc'\n", "\n", "# helpers\n", "import h5py\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import time\n", "from os.path import join\n", "\n", "# need some certainty in data processing\n", "np.random.seed(1234)\n", "tf.random.set_seed(1234)"]}, {"cell_type": "markdown", "metadata": {"id": "tNWOMey2uGNS"}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "ZkWn2ZIAuHcL"}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 17128, "status": "ok", "timestamp": 1646392486809, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "7vqosLs_uJyq", "outputId": "d09c2e54-5c99-45a5-d2c0-2dbea7ba78a1"}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "metadata": {"id": "iagz8L7p1Pec"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "Sp5flta3u0zs"}, "source": ["# 1. Load the dataset\n", "\n", "### Read raw data\n", "\n", "\n", "The INS dataset contains 20,000 images. This number is insufficient to train a GAN, given that the images are of high variability. Each image has a shape of `(20, 200)`, as composed of 10 images with shape `(20, 20)` in a row. To maximise the number of data, we divide one original image into 10 sub-images and filter out the weak ones. Finally, we obtain a dataset with 129,228 images.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# read original images\n", "with h5py.File(join(data_path, 'ins-data/train.h5'), 'r') as handle:\n", "    big_images = handle['images'][:]\n", "    \n", "# divide into 10 sub-images\n", "n = big_images.shape[0]\n", "sub_images = np.moveaxis(big_images.reshape([n, 20, 10, 20]), 2, 1).reshape(n * 10, 20, 20, 1)\n", "    \n", "# plot an image and its sub-images\n", "index = 0\n", "plt.figure(dpi=200)\n", "plt.imshow(big_images[index, :, :, 0])\n", "plt.gca().set_aspect(1.)\n", "plt.axis('off')\n", "plt.show()\n", "fig, ax = plt.subplots(1, 10, dpi=200)\n", "for i in range(10):\n", "    ax[i].imshow(sub_images[index * 10 + i, :, :, 0], vmin=0, vmax=1)\n", "    ax[i].set_aspect(1.)\n", "    ax[i].axis('off')\n", "plt.show()\n", "\n", "# remove weak ones: max pixel smaller than a given threshold\n", "threshold = 0.5\n", "x_train = sub_images[np.where(np.max(sub_images, axis=(1, 2, 3)) > threshold)]\n", "\n", "# normalize to [-1, 1]\n", "x_train = x_train * 2 - 1\n", "\n", "# print size info\n", "print(f'Shape of original dataset: {big_images.shape}')\n", "print(f'Shape of divided dataset: {sub_images.shape}')\n", "print(f'Shape of training dataset: {x_train.shape}')\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 319}, "executionInfo": {"elapsed": 8950, "status": "ok", "timestamp": 1646392496504, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "_yuS7hPJ1Ped", "outputId": "8b2b551b-5557-4b86-cfff-a5fe80f2e2af"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "D6wXheEGyA6m"}, "source": ["Next, we can create a dataset with the new image set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "jk0FI6dtyA6m"}, "outputs": [], "source": ["train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n", "train_dataset = train_dataset.shuffle(1024)\n", "train_dataset = train_dataset.batch(256)"]}, {"cell_type": "markdown", "metadata": {"id": "Yz5ZmXcKwUDf"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "gXtKCXRf1Ped"}, "source": ["# 2. Build the network\n", "\n", "Our image size is `(20, 20)`. We will first build a generator and then a discriminator. The output of the generator and the input of the discriminator should have the same size as the image. \n", "\n", "\n", "### The generator\n", "\n", "The generator takes random noise as inputs and outputs synthetic images, which has the same size with the images in the training dataset.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "def make_generator_model(noise_size=100, image_size=(20,20), n_filters=(256,128,64)):\n", "    '''\n", "    Create a generator, hardcoded with three Conv2DTranspose layers.\n", "\n", "    :param noise_size: size of the seed vector\n", "    :param image_size: size of the image (both width and height must divide 4)\n", "    :param n_filters: number of filters in each layer\n", "    :return: the generator model\n", "    '''\n", "\n", "    # sequential model\n", "    model = tf.keras.Sequential()\n", "\n", "    w = image_size[0] // 4\n", "    h = image_size[1] // 4\n", "    model.add(layers.Dense(w*h*n_filters[0], use_bias=False, \n", "                           input_shape=(noise_size,)))\n", "    model.add(layers.BatchNormalization())\n", "    model.add(layers.LeakyReLU())\n", "\n", "    model.add(layers.Reshape((w, h, n_filters[0])))\n", "\n", "    model.add(layers.Conv2DTranspose(n_filters[1], (5, 5), strides=(1, 1), \n", "                                     padding='same', use_bias=False))\n", "    model.add(layers.BatchNormalization())\n", "    model.add(layers.LeakyReLU())\n", "\n", "    model.add(layers.Conv2DTranspose(n_filters[2], (5, 5), strides=(2, 2), \n", "                                     padding='same', use_bias=False))\n", "    model.add(layers.BatchNormalization())\n", "    model.add(layers.LeakyReLU())\n", "\n", "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), \n", "                                     padding='same', use_bias=False, activation='tanh'))\n", "\n", "    return model\n", "\n", "# noise size\n", "NOISE_SIZE = 100\n", "\n", "# create a generator\n", "generator = make_generator_model(noise_size=NOISE_SIZE, image_size=(20, 20), \n", "                                 n_filters=(256,128,64))\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "87jYoUd-1Ped"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "IPeLO5FX1Pee"}, "source": ["### The discriminator\n", "\n", "The discriminator distinguish between images from the training dataset and outputs from the generator. \n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "def make_discriminator_model(image_size=(20,20), n_filters=(64,128)):\n", "    '''\n", "    Create a discriminator, hardcoded with two Conv2D layers.\n", "\n", "    :param image_size: size of the image (both width and height must divide 4)\n", "    :param n_filters: number of filters in each layer\n", "    :return: the discriminator model\n", "    '''\n", "\n", "    # sequential model\n", "    model = tf.keras.Sequential()\n", "\n", "    w = image_size[0]\n", "    h = image_size[1]\n", "    model.add(layers.Conv2D(n_filters[0], (5, 5), strides=(2, 2), padding='same',\n", "              input_shape=[w, h, 1]))\n", "    model.add(layers.LeakyReLU())\n", "    model.add(layers.Dropout(0.3))\n", "\n", "    model.add(layers.Conv2D(n_filters[1], (5, 5), strides=(2, 2), padding='same'))\n", "    model.add(layers.LeakyReLU())\n", "    model.add(layers.Dropout(0.3))\n", "\n", "    model.add(layers.Flatten())\n", "\n", "    model.add(layers.Dense(1))\n", "\n", "    return model\n", "\n", "# create a discriminator\n", "discriminator = make_discriminator_model(image_size=(20, 20), n_filters=(64,128))\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "hzL8DZlj1Pef"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "BJwU_Zuh1Peg"}, "source": ["### Loss functions and optimizers\n", "\n", "Create the loss functions and optimizers for the generator and discriminator. \n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# cross entropy\n", "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n", "\n", "# discriminator's loss \n", "def discriminator_loss(real_output, fake_output):\n", "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n", "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n", "    total_loss = real_loss + fake_loss\n", "    return total_loss\n", "\n", "# generator's loss\n", "def generator_loss(fake_output):\n", "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n", "\n", "# optimizers\n", "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n", "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "qrr0OkpK1Peg"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "RtnH9DnK1Peh"}, "source": ["### Training Loop\n", "\n", "Implement the training function for a mini-batch. \n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# Notice the use of `tf.function`\n", "# This annotation causes the function to be \"compiled\".\n", "@tf.function\n", "def train_step(real_images, noise_size):\n", "    # seed\n", "    batch_size = real_images.shape[0]\n", "    seed = tf.random.normal([batch_size, noise_size])\n", "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n", "        # fake images\n", "        fake_images = generator(seed, training=True)\n", "\n", "        # discriminate real\n", "        real_score = discriminator(real_images, training=True)\n", "        # discriminate fake\n", "        fake_score = discriminator(fake_images, training=True)\n", "\n", "        # compute losses\n", "        gen_loss = generator_loss(fake_score)\n", "        disc_loss = discriminator_loss(real_score, fake_score)\n", "\n", "        # compute gradients\n", "        gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n", "        disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n", "\n", "        # apply gradients to update model parameters\n", "        generator_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n", "        discriminator_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n", "\n", "        return gen_loss, disc_loss\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "NAkUe-lS1Pei"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "xtTLzXwn1Pei"}, "source": ["Now perform the training. \n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "############################\n", "######### TRAINING #########\n", "############################\n", "\n", "# epochs\n", "EPOCHS = 50\n", "\n", "# epoch loop\n", "tstart = time.time()\n", "for epoch in range(EPOCHS):\n", "    # batch loop\n", "    for i, image_batch in enumerate(train_dataset):\n", "        gen_loss, disc_loss = train_step(image_batch, NOISE_SIZE)\n", "    # print loss after each epoch\n", "    print(f'Epoch {epoch + 1} / {EPOCHS}, Elapsed = {time.time() - tstart:.2f} s, '\n", "          f'Gen loss = {gen_loss:.2f}, Disc loss = {disc_loss:.2f}')\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 2096246, "status": "ok", "timestamp": 1646394596276, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "q3OZcaDi1Pei", "outputId": "ce3e96e4-7401-4e57-84ac-f70f14d2b38a"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "n-Nn7zLNeatA"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "reWb6vdaeXuE"}, "source": ["# 3. Analyse results \n", "\n", "Visualize and comapre the generated images from the generator with images in the training dataset.  "]}, {"cell_type": "markdown", "metadata": {"id": "qXxx58MG1Pej"}, "source": ["Finally, use the trained generator to generate images from random noise. \n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# seed\n", "nrows = 10\n", "ncols = 10\n", "seed = tf.random.normal([nrows * ncols, NOISE_SIZE])\n", "\n", "# generate images\n", "generated_image = generator(seed, training=False)\n", "\n", "# plot images\n", "plt.figure(dpi=100, figsize=(ncols, nrows))\n", "for iplot in range(nrows * ncols):\n", "    plt.subplot(nrows, ncols, iplot + 1)\n", "    plt.imshow(generated_image[iplot, :, :, 0])\n", "    plt.xticks([])\n", "    plt.yticks([])\n", "plt.show()\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 796}, "executionInfo": {"elapsed": 4268, "status": "ok", "timestamp": 1646394600531, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "fXdupl8hebsX", "outputId": "883aea57-59a8-4635-afda-85d629f09c95"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "K1ySTssIy3Ol"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "j5xYWMA1y4wn"}, "source": ["# 4. Exercise\n", "\n", "* Change learning rates of a generator and a discriminator\n", "* Try to use different loss functions to make learning GANs stable such as Wasserstein GAN\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "jwcXr_hde10t"}, "outputs": [], "source": []}], "metadata": {"accelerator": "GPU", "colab": {"collapsed_sections": [], "name": "Material_GAN Graphene EM Images_solution.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 1}