{"cells": [{"cell_type": "markdown", "metadata": {"id": "w3R6nQ4udhNo"}, "source": ["# 0. Predicting beam profile in synchrotron beam using LSTM\n", "\n", "In this notebook, we attempt to build a time series model to predict the profile of the beam, specifically the RMS of the x-coordinate profile.\n", "\n", "\n", "The data in this example has several parameters as inputs.  We have the horizontal and vertical control of the injector that control the incoming beam. We also have the time that the acceleration has been running for and finally we have an estimate of the number of the profile.\n", "\n", "\n", "The aim of this work is to take the results of the low cost simulation and to use the LSTM make them match more closely to the high cost accurate simulation - which is your ground truth Y values in this example. To give a sense of the sppedup, the low cost simulations take about 1 second to run, the ground truth simulations take about 16 hours each.\n", "\n", "The data for this practical is plotted below. On the left you can see the vertical and horizontal injector control paramaters. On the right you can see the X$_{RMS}$ from the low cost model and those from the full physics simulation.\n", "\n", "<img src=\"https://github.com/stfc-sciml/sciml-workshop-v3/blob/master/course_3.0_with_solutions/markdown_pic/lstm-practical-data.png?raw=1\" alt=\"lstm-practical-data\" width=\"900\"/>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 3251, "status": "ok", "timestamp": 1646396336591, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "PoaxKFdbdhNs", "outputId": "b9541073-29db-4248-8b63-c34ffec34db7"}, "outputs": [], "source": ["# tensorflow\n", "import tensorflow as tf\n", "from tensorflow.keras.layers import LSTM\n", "from tensorflow.keras.layers import Dropout\n", "from tensorflow.keras.layers import Input, Dense\n", "from tensorflow.keras.models import Model\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.callbacks import EarlyStopping\n", "\n", "# check version\n", "print('Using TensorFlow v%s' % tf.__version__)\n", "acc_str = 'accuracy' if tf.__version__[:2] == '2.' else 'acc'\n", "\n", "# helpers\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "from sklearn.preprocessing import MinMaxScaler\n", "from os.path import join\n", "\n", "# need some certainty in data processing\n", "np.random.seed(1234)\n", "tf.random.set_seed(1234)"]}, {"cell_type": "markdown", "metadata": {"id": "NDARGbjQfHkm"}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "metadata": {"executionInfo": {"elapsed": 12463, "status": "ok", "timestamp": 1646396354215, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "X-hpByuYfBXf"}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 16043, "status": "ok", "timestamp": 1646396370253, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "cjmXBQ85fJ_Z", "outputId": "92e2d362-ac16-4918-da7a-29580b092f31"}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "metadata": {"id": "EoiLipIOfNjO"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "LFVUs6h0dhNt"}, "source": ["# 1. Load the dataset\n", "\n", "### Read raw data\n", "\n", "The data has been preprocessed a bit - so the values are all normalised to between 0 and 1. Use `pandas` to read the csv `Material/injector-data.csv`\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "data = pd.read_csv(join(data_path,'Material/injector-data.csv'))\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"executionInfo": {"elapsed": 765, "status": "ok", "timestamp": 1646396371014, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "et-Sq_0QdhNt"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "YxrgkdagdhNu"}, "source": ["### Our data processing for LSTM function\n", "\n", "In order to provide data to LSTM, we need to convert data to time series."]}, {"cell_type": "code", "execution_count": null, "metadata": {"executionInfo": {"elapsed": 225, "status": "ok", "timestamp": 1646396401216, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "YVBz1uUvdhNu"}, "outputs": [], "source": ["# convert series to supervised learning\n", "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n", "    \"\"\"\n", "    Frame a time series as a supervised learning dataset.\n", "    The function automatically checks if we are dealing with a univariate or a multi-variate problem, by  \n", "    checing the shape and type of `data`.\n", "    Adapted from: https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n", "    Arguments:\n", "       data: Sequence of observations as a list or NumPy array.\n", "       n_in: Number of lag observations as input (X).\n", "       n_out: Number of observations as output (y).\n", "       dropnan: Boolean whether or not to drop rows with NaN values.\n", "    Returns:\n", "       Pandas DataFrame of series framed for supervised learning.\n", "    \"\"\"\n", "    n_vars = 1 if type(data) is list else data.shape[1]\n", "    df = pd.DataFrame(data)\n", "    cols, names = list(), list()\n", "    # input sequence (t-n, ... t-1)\n", "    for i in range(n_in, 0, -1):\n", "        cols.append(df.shift(i))\n", "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n", "    # forecast sequence (t, t+1, ... t+n)\n", "    for i in range(0, n_out):\n", "        cols.append(df.shift(-i))\n", "        if i == 0:\n", "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n", "        else:\n", "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n", "    # put it all together\n", "    agg = pd.concat(cols, axis=1)\n", "    agg.columns = names\n", "    # drop rows with NaN values\n", "    if dropnan:\n", "        agg.dropna(inplace=True)\n", "    return agg"]}, {"cell_type": "markdown", "metadata": {"id": "XLNN3J_qdhNv"}, "source": ["### Split into x and y values\n", "\n", "In this example the coluumns 1-4 of the data are the input variables and column 5 is the value we wish to predict. In the first instance we will just use the first 100000 data points to train the model. Limiting the data this way results in over-fitting, **but** it will allow us to get the model working and training in a reasonable time.\n", "\n", "When we are happy that the model is actually training and learning (albeit over-fitting) we can return and add more data. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"executionInfo": {"elapsed": 2, "status": "ok", "timestamp": 1646396401217, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "tz8EQ8lqdhNv"}, "outputs": [], "source": ["data_limit = 100000\n", "values = data.values\n", "xvalues = values[:data_limit, 1:5]\n", "yvalues = values[:data_limit, 5]"]}, {"cell_type": "markdown", "metadata": {"id": "B8nemyrGdhNw"}, "source": ["### Refreame the training data\n", "\n", "Use the `series_to_supervised` function to convert the `xvalues` to a datframe called `reframedx` which has a past window of 0 steps into the past and a future prediction window of 1 step.\n", "\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "reframedx = series_to_supervised(xvalues, 0, 1)\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"executionInfo": {"elapsed": 213, "status": "ok", "timestamp": 1646396403202, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "2UASR5W8dhNw"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "jPMQsWS_dhNw"}, "source": ["### Convert to arrays for training\n", "\n", "We now reshape the `reframedx` to work with the netword. **Note** we also need to remove the first $n$ values from the y data, where $n$ is the size of the window defined above. When you are tyring different window sizes in future, don't forget to alter this value."]}, {"cell_type": "code", "execution_count": null, "metadata": {"executionInfo": {"elapsed": 4, "status": "ok", "timestamp": 1646396403440, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "0XTobwBydhNx"}, "outputs": [], "source": ["past_steps = 0\n", "x_train = reframedx.values\n", "x_train = x_train.reshape((x_train.shape[0], 4, x_train.shape[1]//4))\n", "y_train = yvalues[past_steps:]"]}, {"cell_type": "markdown", "metadata": {"id": "B8RUaTjHfuF-"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "O7hIEG33dhNx"}, "source": ["# 2. Build the network\n", "\n", "We will build a network with LSTM layer. The first layer is a LSTM layer and it takes a time seris input. Hence, the input shape should be (n of time stamp, n of features). Then, the last layer of the network should output one target feature. \n", "\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# Initialising the LSTM\n", "model = Sequential()\n", "\n", "# Adding the first LSTM layer and some Dropout regularisation\n", "model.add(LSTM(50, return_sequences = False, input_shape=(x_train.shape[1], x_train.shape[2])))\n", "\n", "# Adding the output layer\n", "model.add(Dense(1))\n", "print(model.summary())\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 650, "status": "ok", "timestamp": 1646396405829, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "5_wf4WBOdhNx", "outputId": "2e44f84b-6d62-4dec-efee-005bb0dfb297"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "XBy2RwDWdhNy"}, "source": ["## Compile and fit the network\n", "\n", "Compile the network to use `mae` as the loss and `adam` as the optimiser.\n", "\n", "For training initially run for 30 epochs with a batch size of 128 and a validation split of 0.2. Set `shuffle` to `False` for the fitting.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "stopper=EarlyStopping( monitor =\"val_loss\", min_delta=0.0,verbose=1,\n", "                      mode=\"min\",\n", "                      restore_best_weights=True,patience=2)\n", "\n", "model.compile(loss='mae', optimizer='adam')\n", "history = model.fit(x_train, y_train, epochs=30, \n", "                    batch_size=128, validation_split=0.2, \n", "                    shuffle=False,callbacks=[stopper])\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 13748, "status": "ok", "timestamp": 1646396421072, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "2z5JkPWQdhNy", "outputId": "184b0cf0-66da-445e-c600-1e691a66d42d"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "rLag_59Nir98"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "arRMsXKWis07"}, "source": ["# 3. Analyse results "]}, {"cell_type": "markdown", "metadata": {"id": "4l9-u3pSdhNy"}, "source": ["## Take a look at some results\n", "\n", "We can look at how the model peroforms on the training set and on an independent test set.\n", "\n", "### Training set\n", "\n", "First see how we are doing on the training data - if you cannot fit the training data there is no hope on anything else. \n", "By chaniging the value of `index` below we can choose different samples from the training set."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 353}, "executionInfo": {"elapsed": 1561, "status": "ok", "timestamp": 1646396483242, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "95zZT_xDdhNz", "outputId": "cb95a731-fe89-429e-81f9-384b8caaba6f"}, "outputs": [], "source": ["index = 1\n", "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n", "y_pred = model.predict(x_train[(index-1)*786+100:index*786])\n", "plt.plot(y_pred[:, 0], label='Prediction')\n", "plt.plot(y_train[(index-1)*786:index*786], label='True')\n", "plt.title('RMS of the x-coordinate profile prediction on the training set')\n", "plt.legend()\n", "plt.xlim(0, 660)"]}, {"cell_type": "markdown", "metadata": {"id": "pUHnH66xdhNz"}, "source": ["### Independent test set\n", "\n", "If the model worked okay on the training data a true test is on independent data that was not used for training.\n", "\n", "**Note** you will have to alter window size here to match your training data."]}, {"cell_type": "code", "execution_count": null, "metadata": {"executionInfo": {"elapsed": 231, "status": "ok", "timestamp": 1646396488730, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "8FWwI-wIdhNz"}, "outputs": [], "source": ["window_size = 0\n", "values = data.values\n", "xtestvalues = values[370913:, 1:5]\n", "ytestvalues = values[370913:, 5]\n", "reframedxtest = series_to_supervised(xtestvalues, window_size, 1)\n", "x_test = reframedxtest.values\n", "x_test = x_test.reshape((x_test.shape[0], 4, x_test.shape[1]//4))\n", "y_test = ytestvalues[window_size:]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 353}, "executionInfo": {"elapsed": 654, "status": "ok", "timestamp": 1646396494060, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "Ocgt0v_wdhNz", "outputId": "035a13fd-f164-40fb-92e0-3b98782fbc67"}, "outputs": [], "source": ["index = 10\n", "y_pred = model.predict(x_test[(index-1)*786:index*786])\n", "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n", "plt.plot(y_pred[100:, 0], label='Prediction')\n", "plt.plot(y_test[(index-1)*786:index*786], label='True')\n", "plt.title('RMS of the x-coordinate profile prediction on the test set')\n", "plt.legend()\n", "plt.xlim(100, 680)"]}, {"cell_type": "markdown", "metadata": {"id": "V7uqKQopdW7B"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "EyWl9UOTdhNz"}, "source": ["# 4. Exercise\n", "\n", "The network is running, but the results are not very good. Let's try doing some hyper-parameter tuning. \n", "\n", "Here are some things to try:\n", "\n", "* Different window sizes\n", "    - [0, 1, 2, 5, 10]\n", "    - Use just 30 epochs for each of these\n", "    \n", "* Increase the number of LSTM layers\n", "    - 1, 2, 3 layers of lstm\n", "    - Use just 30 epochs for each of there\n", "    \n", "When you have found the best options - try to increase the training dataset to 400000 and leave the model to train for 1000 epochs. This will probably take quite a long time, so you might want to leave this running overnight.\n", "\n", "**Sample code for hyper-parameter tuning: window size** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "import tqdm as tqdm\n", "steps = [0, 1, 2, 5, 10]\n", "histories = []\n", "for step in tqdm.tqdm(steps):\n", "    reframedx = series_to_supervised(xvalues, step, 1)\n", "    past_step = step\n", "    x_train = reframedx.values\n", "    x_train = x_train.reshape((x_train.shape[0], 4, x_train.shape[1]//4))\n", "    ytrain = yvalues[past_step:]\n", "    # Initialising the LSTM\n", "    model = Sequential()\n", "\n", "    # Adding the first LSTM layer and some Dropout regularisation\n", "    model.add(LSTM(units = 50, return_sequences = False, input_shape=(x_train.shape[1], x_train.shape[2])))\n", "\n", "    model.add(Dense(units = 1))\n", "    model.compile(loss='mae', optimizer='adam')\n", "    history = model.fit(x_train, ytrain, epochs=30, \n", "                    batch_size=128, validation_split=0.2, \n", "                    shuffle=False, verbose=0)\n", "    histories.append(history)\n", "    \n", "fig, ax, = plt.subplots(1, 1, figsize=(7, 7))\n", "for i in range(5):\n", "    plt.plot(histories[i].history['val_loss'], label='%s'%i, lw=2)\n", "plt.legend()\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "WnioCr0SdhNz"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "2cWvioG8dhN0"}, "source": ["**Sample code for hyper-parameter tuning: number of LSTMs** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "lstms = [1, 2, 3]\n", "step = 5\n", "histories_lstm = []\n", "for lstm in tqdm.tqdm(lstms):\n", "    reframedx = series_to_supervised(xvalues, step, 1)\n", "    past_step = step\n", "    x_train = reframedx.values\n", "    x_train = x_train.reshape((x_train.shape[0], 4, x_train.shape[1]//4))\n", "    ytrain = yvalues[past_step:]\n", "    # Initialising the LSTM\n", "    model = Sequential()\n", "    if lstm == 1:\n", "    # Adding the first LSTM layer and some Dropout regularisation\n", "        model.add(LSTM(units = 50, return_sequences = False, input_shape=(x_train.shape[1], x_train.shape[2])))\n", "    elif lstm == 2:\n", "        model.add(LSTM(units = 50, return_sequences = True, input_shape=(x_train.shape[1], x_train.shape[2])))\n", "        model.add(LSTM(units = 50, return_sequences = False))\n", "    elif lstm == 3:\n", "        model.add(LSTM(units = 50, return_sequences = True, input_shape=(x_train.shape[1], x_train.shape[2])))\n", "        model.add(LSTM(units = 50, return_sequences = True))\n", "        model.add(LSTM(units = 50, return_sequences = False))\n", "        \n", "        \n", "    model.add(Dense(units = 1))\n", "    model.compile(loss='mae', optimizer='adam')\n", "    history = model.fit(x_train, ytrain, epochs=30, \n", "                    batch_size=128, validation_split=0.2, \n", "                    shuffle=False, verbose=0)\n", "    histories_lstm.append(history)    \n", "    \n", "fig, ax, = plt.subplots(1, 1, figsize=(7, 7))\n", "for i in range(3):\n", "    plt.plot(histories_lstm[i].history['val_loss'], label='%s'%i, lw=2)\n", "plt.legend()\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "JWZEW_D0dhN0"}, "outputs": [], "source": []}], "metadata": {"colab": {"collapsed_sections": [], "name": "Material_Beam profile in synchrotron beam prediction_solution.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 1}