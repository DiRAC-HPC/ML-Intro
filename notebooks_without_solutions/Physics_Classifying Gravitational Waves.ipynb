{"cells": [{"cell_type": "markdown", "id": "fa356104", "metadata": {"id": "fa356104"}, "source": ["# 0. Gravitational waves classification\n", "\n", "In this notebook, we attempt to build a neural network to classify gravitational waves and pure noise signals. \n", "\n", "Gravitational waves are disturbances in the curvature of spacetime, generated by accelerated masses, that propagate as waves outward from their source at the speed of light. Although they ripple, in real scenario most signals are obtained with noise and so they cannot be visually distinguished from noise signals. The gravitational waves are generated with using the [LALSuite IMRPhenomD generator](https://arxiv.org/pdf/1508.07250.pdf).\n", "\n", "The aim of this work is to classify gravitation waves and pure noise signals using 1d convolutional and dense layers. \n"]}, {"cell_type": "code", "execution_count": null, "id": "da80c42b", "metadata": {"id": "da80c42b"}, "outputs": [], "source": ["from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Multiply, Add, Flatten, Dropout\n", "from tensorflow.keras.models import Model\n", "from tensorflow.keras import Sequential\n", "from tensorflow.keras.callbacks import EarlyStopping\n", "import tensorflow as tf\n", "\n", "# sklearn\n", "from sklearn import metrics\n", "from sklearn import svm\n", "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n", "from sklearn.ensemble import GradientBoostingRegressor\n", "import sklearn.datasets\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.preprocessing import OneHotEncoder\n", "\n", "# helpers\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from os.path import join\n"]}, {"cell_type": "markdown", "id": "e3b56e41", "metadata": {"id": "e3b56e41"}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "id": "c134b330", "metadata": {"id": "c134b330"}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "id": "a2dcef77", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 16397, "status": "ok", "timestamp": 1646401000477, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "a2dcef77", "outputId": "bb2ae118-1001-4a58-8a8b-1b0e3fbff1ff"}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "id": "8a7db43b", "metadata": {"id": "8a7db43b"}, "source": ["---"]}, {"cell_type": "markdown", "id": "adff0d6e", "metadata": {"id": "adff0d6e"}, "source": ["# 1. Load the dataset\n", "\n", "### Read raw data\n", "\n", "The data is stored in 'Physics/gravitational_wave_dataset.npz', containing 2,000 signals: 1,000 examples of signals and 1,000 examples of pure noise. The signals are 1 second long with a sample rate of 8196.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "grav_wave = np.load(join(data_path, 'Physics/gravitational_wave_dataset.npy'), allow_pickle=True)\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "2f3ebfdd", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "85a4b56a", "metadata": {"id": "85a4b56a"}, "outputs": [], "source": ["def prepare_datset(X, target = 'regression'):\n", "    if target == 'regression':\n", "        x = np.expand_dims(np.sum(np.stack(X[:1000, 2]), axis = -1), axis = -1).astype(np.float32)\n", "        y = np.stack([[w[0] for w in  grav_wave[j, [3, 4]]] for j in np.arange(1000)])\n", "        y = y.reshape(len(x), 2).astype(np.float32)\n", "        \n", "    elif target == 'classification':\n", "        x = np.expand_dims(np.sum(np.stack(X[:, 1]), axis = -1), axis = -1)\n", "        y = X[:, 0].astype(np.int)\n", "        \n", "    return x, y\n", "        \n", "    "]}, {"cell_type": "markdown", "id": "1d90bd7f", "metadata": {}, "source": ["Prepare a dataset for a classification task using the prepare_dataset function and split it using the train_test_split funtion\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "x, y = prepare_datset(grav_wave, target = 'classification')\n", "\n", "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n", "\n", "print('x_train shape: ', x_train.shape)\n", "print('y_train shape: ', y_train.shape)\n", "print('x_test shape: ', x_test.shape)\n", "print('y_test shape: ', y_test.shape)    \n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "a8b27671", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 10329, "status": "ok", "timestamp": 1646401021867, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "a8b27671", "outputId": "a5501dcb-9bd9-4fc8-e760-d4d54e782532"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "12a58d4b", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 444}, "executionInfo": {"elapsed": 2255, "status": "ok", "timestamp": 1646401024116, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "12a58d4b", "outputId": "cacf1a86-08c6-466e-8b60-17d97ccd9982"}, "outputs": [], "source": ["fig, axes = plt.subplots(2, 5, figsize = (16, 7))\n", "\n", "for i in range(2):\n", "    sub_idx = np.where(y_train == i)[0]\n", "    for j in range(5):\n", "        axes[i][j].plot(x_train[sub_idx[j]])\n", "        axes[i][j].set_title('Gravitational waves' if i ==0 else 'Noise')"]}, {"cell_type": "markdown", "id": "a1ea2247", "metadata": {"id": "a1ea2247"}, "source": ["---"]}, {"cell_type": "markdown", "id": "8beda1f2", "metadata": {"id": "8beda1f2"}, "source": ["# 2. Build the network\n", "\n", "We will build a support vector machine (SVM) and a 1D-convolutional neural network to compare their results.\n", "\n"]}, {"cell_type": "markdown", "id": "dacca667", "metadata": {"id": "dacca667"}, "source": ["### Support Vector Machine\n", "\n", "Use SVM from sklearn library.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# fit linear regression model\n", "model = svm.SVC().fit(x_train.reshape(-1, 8192), y_train)\n", "# make predictions\n", "y_train_pred = model.predict(x_train.reshape(-1, 8192))\n", "y_test_pred = model.predict(x_test.reshape(-1, 8192))\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "cafb30c8", "metadata": {"id": "cafb30c8"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "b27c7605", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 15, "status": "ok", "timestamp": 1646401091705, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "b27c7605", "outputId": "d76653ba-542c-4268-f74b-11e0f4107f78"}, "outputs": [], "source": ["# compute some fitting error\n", "print('Accuracy on the train set = %f ' % metrics.accuracy_score(y_train, y_train_pred))\n", "print('Accuracy on the test set = %f ' % metrics.accuracy_score(y_test, y_test_pred))"]}, {"cell_type": "markdown", "id": "7d2396d8", "metadata": {"id": "7d2396d8"}, "source": ["### Build a Neural Network\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "model = Sequential()\n", "model.add(Input(shape=(x_train.shape[1],1,)))\n", "\n", "model.add(Conv1D(filters=16, kernel_size=7, strides = 2, activation='relu'))\n", "model.add(MaxPooling1D(2))\n", "model.add(Conv1D(filters=32, kernel_size=7, strides = 2, activation='relu'))\n", "model.add(MaxPooling1D(2))\n", "model.add(Flatten())\n", "model.add(Dense(1024, activation=\"relu\"))\n", "model.add(Dropout(0.2))\n", "\n", "model.add(Dense(1, activation = \"sigmoid\"))        \n", "\n", "opt = tf.keras.optimizers.Adam(0.0001)\n", "model.compile(loss=\"binary_crossentropy\", optimizer=opt)\n", "\n", "\n", "\n", "stopper=EarlyStopping(monitor =\"val_loss\", min_delta=0.0,verbose=1,\n", "                      mode=\"min\", restore_best_weights=True,patience=5)\n", "history = model.fit(x_train, y_train, epochs=99, batch_size=64, \n", "                             validation_split=0.2,callbacks=[stopper])\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "59fb706e", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 325043, "status": "ok", "timestamp": 1646401416741, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "59fb706e", "outputId": "62570da8-90ba-4586-bcc3-39e3ef7ff1f9"}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "2a35341a", "metadata": {"id": "2a35341a"}, "source": ["---"]}, {"cell_type": "markdown", "id": "1e57546b", "metadata": {"id": "1e57546b"}, "source": ["# 3. Analyse results "]}, {"cell_type": "markdown", "id": "2f66250a", "metadata": {"id": "2f66250a"}, "source": ["### prediction\n", "\n", "We used the sigmoid function. Hence, the label will be 1 if the output is greater than 0.5 and 0 otherwise.\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "y_train_pred = model.predict(x_train)\n", "y_test_pred = model.predict(x_test)\n", "\n", "y_train_pred = np.where(y_train_pred>0.5, 1., 0.)\n", "y_test_pred = np.where(y_test_pred>0.5, 1., 0.)\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "id": "cc314043", "metadata": {"id": "cc314043"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "6955b5ab", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 13, "status": "ok", "timestamp": 1646401420601, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "6955b5ab", "outputId": "21e67f8d-0189-4e6b-eca0-1923e0ad78e5"}, "outputs": [], "source": ["# compute some fitting error\n", "print('Accuracy on the train set = %f ' % metrics.accuracy_score(y_train, y_train_pred.reshape(-1)))\n", "print('Accuracy on the test set = %f ' % metrics.accuracy_score(y_test, y_test_pred.reshape(-1)))"]}, {"cell_type": "code", "execution_count": null, "id": "f51f63bc", "metadata": {"id": "f51f63bc"}, "outputs": [], "source": ["agree_idxs = np.where(y_test == y_test_pred.reshape(-1))[0]\n", "disagree_idxs = np.where(y_test!=y_test_pred.reshape(-1))[0]"]}, {"cell_type": "code", "execution_count": null, "id": "78b83870", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 545}, "executionInfo": {"elapsed": 680, "status": "ok", "timestamp": 1646401421274, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "78b83870", "outputId": "aa77d1d0-8df8-4a92-b0a8-612efd145cbf"}, "outputs": [], "source": ["for _ in range(len(disagree_idxs)):\n", "    agree_idx = np.random.choice(len(agree_idxs), 1)[0]\n", "    plt.figure()\n", "    plt.plot(x_test[agree_idx])\n", "    plt.title('Label is {} and predicted as {}'.format(y_test[agree_idx], int(y_test_pred[agree_idx][0])))"]}, {"cell_type": "code", "execution_count": null, "id": "e354863e", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 545}, "executionInfo": {"elapsed": 696, "status": "ok", "timestamp": 1646401421959, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "e354863e", "outputId": "fc93b683-ab0e-46e0-db3c-afe2b5e9da63"}, "outputs": [], "source": ["for disagree_idx in disagree_idxs:\n", "    plt.figure()\n", "    plt.plot(x_test[disagree_idx])\n", "    plt.title('Label should be {} but is predicted as {}'.format(y_test[disagree_idx], int(y_test_pred[disagree_idx][0])))"]}, {"cell_type": "markdown", "id": "6ff02411", "metadata": {"id": "6ff02411"}, "source": ["---"]}, {"cell_type": "markdown", "id": "918069a2", "metadata": {"id": "918069a2"}, "source": ["# 4. Exercises\n", "\n", "* Change some hyperparameters in `model.compile()` and `model.fit()` to see their effects (see reference of [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)); \n", "* Change the architeture and activation functions of neural networks to improve the accuracy"]}, {"cell_type": "code", "execution_count": null, "id": "2271a813", "metadata": {"id": "2271a813"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "0f83f698", "metadata": {"id": "0f83f698"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "d05eac99", "metadata": {"id": "d05eac99"}, "outputs": [], "source": []}], "metadata": {"colab": {"collapsed_sections": [], "name": "Physics_LIGOWAVE 1D classification_solution.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}