{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 0. SKA continuum image classification using convolutional neural networks\n", "\n", "In this notebook, we attempt to classify simulated SKA continuum image using convolutional neural networks.\n", "\n", "\n", "The data is a simulated SKA continuum image in total intensity of the same field at 560 MHz, representative of SKA Mid Band 1 and a 8 hour telescope integration, representative of a single. More details can be found in the [SKA SCIENCE DATA CHALLENGE 1](https://astronomers.skatelescope.org/wp-content/uploads/2018/11/SKA-TEL-SKO-0001001-SKA_DataChallengesDataDescription-signed.pdf). \n", "\n", "\n", "The aim of this work is to train a neural network to classify active galactic nucles (AGNs) and star forming galaxies (SFGs).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# tensorflow\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\n", "\n", "# check version\n", "print('Using TensorFlow v%s' % tf.__version__)\n", "acc_str = 'accuracy' if tf.__version__[:2] == '2.' else 'acc'\n", "\n", "# helpers\n", "import h5py\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from os.path import join\n", "\n", "# need some certainty in data processing\n", "np.random.seed(1234)\n", "tf.random.set_seed(1234)\n", "\n", "data_path = 'data'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 1. Load the dataset\n", "\n", "### Read raw data\n", "\n", "We have already split the data into training and validation sets and saved them into two HDF5 files, `Astronomy/scd2d_13_train.h5` and `Astronomy/scd2d_13_test.h5`, containing respectively 80% and 20% of images and their one-hot encoded labels identifying an image as either being of the *AGNs* or *SFGs*. \n", "\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "with h5py.File(join(data_path, 'Astronomy/scd2d_64_train.h5'), 'r') as F:\n", "    x_train = np.array(F['images'])\n", "    y_train = np.array(F['labels'])            \n", "            \n", "with h5py.File(join(data_path, 'Astronomy/scd2d_64_test.h5'), 'r') as F:\n", "    x_test = np.array(F['images'])\n", "    y_test = np.array(F['labels'])\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# define image size\n", "IMG_HEIGHT = 64\n", "IMG_WIDTH = 64\n", "N_CHANNELS = 1\n", "N_CLASSES = 2\n", "    \n", "# string labels\n", "string_labels = ['AGNs', 'SFGs']\n", "\n", "# print\n", "print(\"Number of training data: %d\" % len(x_train))\n", "print(\"Number of test data: %d\" % len(x_test))\n", "print(\"Image pixels: %s\" % str(x_train[0, :, :, 0].shape))\n", "print(\"Number of channels: %s\" % str(x_train.shape[-1]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Load and use data\n", "\n", "In the following cell, we will load the first buffer (with 32 data by default) to memory and plot some images and labels from it:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# plot some images and labels from it\n", "fig, axes = plt.subplots(N_CLASSES, 5, figsize=(12, 5))\n", "for i in range(N_CLASSES):\n", "    y_sub = np.random.choice(np.where(y_train == i)[0], 5)\n", "    for j in range(5):\n", "        axes[i][j].matshow(np.squeeze(x_train[y_sub[j]]))\n", "        axes[i][j].set_xlabel('label: ' + string_labels[i])\n", "        axes[i][j].set_xticks([])\n", "        axes[i][j].set_yticks([])\n", "        "]}, {"cell_type": "markdown", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 2. Build the network\n", "\n", "In this case, we have binary classification. We can deal with binary classification by outputing 1 value and using 'binary_crossentropy'.\n", "\n", "\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# network architecture\n", "model = Sequential()\n", "model.add(Conv2D(32, kernel_size=(5, 5), strides = 2, activation='relu', padding='same',\n", "                 input_shape=(IMG_HEIGHT, IMG_WIDTH, N_CHANNELS)))\n", "model.add(MaxPool2D(pool_size=(2, 2)))\n", "model.add(BatchNormalization())\n", "model.add(Conv2D(64, kernel_size=(3, 3), strides = 2, activation='relu', padding='same'))\n", "model.add(MaxPool2D(pool_size=(2, 2)))\n", "model.add(BatchNormalization())\n", "model.add(Flatten())\n", "model.add(Dense(1, activation = \"sigmoid\"))  \n", "\n", "# print summary\n", "model.summary()\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### metrics\n", "\n", "We can add the following metrics to see how the network performs for the two classes:\n", "\n", "* `TruePositives`: number of right predictions for AGNs\n", "* `FalsePositives`: number of wrong predictions for AGNs\n", "* `TrueNegatives`: number of right predictions for SFGs\n", "* `FalseNegatives`: number of wrong predictions for SFGs\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# compile the model\n", "opt = keras.optimizers.Adam(learning_rate=0.01)\n", "model.compile(optimizer=opt, loss=\"binary_crossentropy\", \n", "              metrics= ['accuracy',\n", "                        keras.metrics.TruePositives(name='true_positives'),\n", "                        keras.metrics.FalsePositives(name='false_positives'),\n", "                        keras.metrics.TrueNegatives(name='true_negatives'),\n", "                        keras.metrics.FalseNegatives(name='false_negatives')])\n", "```\n", "    \n", "</p>\n", "</details>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Train the model\n", "\n", "Using the suggested architecture, we can achieve an accuracy greater than 95% with 2 epochs. \n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# train the model\n", "training_history = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n", "                             epochs=20, batch_size=64)\n", "\n", "# print final values of metrics for validation data\n", "print('Right for AGNs: %d' % training_history.history['val_true_positives'][-1])\n", "print('Wrong for AGNs: %d' % training_history.history['val_false_positives'][-1])\n", "print('Right for SFGs: %d' % training_history.history['val_true_negatives'][-1])\n", "print('Wrong for SFGs: %d' % training_history.history['val_false_negatives'][-1])\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 3. Analyse results "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Plot training history\n", "\n", "For convenience, we define a function to plot a training history:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# a function to plot training history\n", "def plot_history(training_history):\n", "    # plot accuracy\n", "    plt.figure(dpi=100, figsize=(12, 4))\n", "    plt.subplot(1, 2, 1)\n", "    plt.plot(training_history.history[acc_str], label='Accuracy on training data')\n", "    plt.plot(training_history.history['val_' + acc_str], label='Accuracy on test data')\n", "    plt.legend()\n", "    plt.title(\"Accuracy\")\n", "\n", "    # plot loss\n", "    plt.subplot(1, 2, 2)\n", "    plt.plot(training_history.history['loss'], label='Loss on training data')\n", "    plt.plot(training_history.history['val_loss'], label='Loss on test data')\n", "    plt.legend()\n", "    plt.title(\"Loss\")\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# plot training history\n", "plot_history(training_history)\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 4. Exercises\n", "\n", "* Change some hyperparameters in `model.compile()` and `model.fit()` to see their effects (see reference of [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)); \n", "* Change the architeture and activation functions of neural networks to improve the accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 2}