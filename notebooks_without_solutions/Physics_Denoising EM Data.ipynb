{"cells": [{"cell_type": "markdown", "metadata": {"id": "EJ3JOghMWIO1"}, "source": ["# 0. Noise removal with autoencoders\n", "\n", "In this notebook, we attempt to remove noise to obtain clean images using autoencoders.\n", "\n", "The surfaces of many particles are extremely rough. As a result, various imaging techniques struggle to obtain clean images due to a common interference phenomenon called speckle. \n", "\n", "Speckle is a granular interference that inherent and degrades the quality of the active radar, synthetic aperture radar (SAR), medical ultrasound, and optical coherence tomography images. This unwanted modification of the ground truth makes the recorded data noisy.  \n", "\n", "In this example, we remove the speckle using an autoencoder.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 6750, "status": "ok", "timestamp": 1646404729772, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "kaKRrcCOWIO3", "outputId": "cbd71878-170b-446d-a731-85363f1d90b5"}, "outputs": [], "source": ["# tensorflow\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras import layers\n", "\n", "# check version\n", "print('Using TensorFlow v%s' % tf.__version__)\n", "acc_str = 'accuracy' if tf.__version__[:2] == '2.' else 'acc'\n", "\n", "# helpers\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import h5py\n", "from sklearn.model_selection import train_test_split\n", "from os.path import join\n", "\n", "# need some certainty in data processing\n", "np.random.seed(1234)\n", "tf.random.set_seed(1234)"]}, {"cell_type": "markdown", "metadata": {"id": "RVfo3QzTWIO5"}, "source": ["## Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press `Enter`;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called `sciml-workshop-data` should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "C9iaCtOJWIO7"}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 17317, "status": "ok", "timestamp": 1646404765635, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "eKkhdXKmWIO7", "outputId": "707e9b0c-15e3-43f5-f0f2-4741518bbed8"}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "metadata": {"id": "Ow7ahKjaWIO8"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "3gZVVSCpWIO9"}, "source": ["# 1. Load the dataset\n", "\n", "### Read raw data\n", "\n", "The data is stored in 'Physics/speckles.npz', containing 25484, gray-scale, 64 \u00d7 64 images. We will use 80% of images to train neural networks and the rest of them to evaluate the neural networks. The details of the data can be found in https://nbviewer.org/github/DeepLearningForPhysicsResearchBook/deep-learning-physics/blob/main/Exercise_17_1.ipynb.\n", "\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "f = np.load(join(data_path, 'Physics/speckles.npz'))\n", "\n", "noised_img = f['speckle_images']\n", "clean_img = f['target_images']\n", "\n", "max_pixel = np.max(noised_img, axis=(1, 2, 3), keepdims=True)\n", "\n", "noised_img = noised_img/max_pixel\n", "clean_img = clean_img/max_pixel\n", "\n", "n_train = int(len(noised_img)*0.8)\n", "\n", "x_train = noised_img[:n_train]\n", "y_train = clean_img[:n_train]\n", "\n", "\n", "x_test = noised_img[n_train:]\n", "y_test = clean_img[n_train:]\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 10577, "status": "ok", "timestamp": 1646404776209, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "8v5BPfY_WIO-", "outputId": "bb833c0f-d399-49db-b0ab-f6e18fcee0d3"}, "outputs": [], "source": ["# define image size\n", "IMG_HEIGHT = 64\n", "IMG_WIDTH = 64\n", "N_CHANNELS = 1\n", "N_CLASSES = 2\n", "\n", "\n", "# print\n", "print(\"Number of training data: %d\" % len(x_train))\n", "print(\"Number of test data: %d\" % len(x_test))\n", "print(\"Image pixels: %s\" % str(x_train[0, :, :, 0].shape))\n", "print(\"Number of channels: %s\" % str(x_train.shape[-1]))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 264}, "executionInfo": {"elapsed": 1025, "status": "ok", "timestamp": 1646404777229, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "xjJQoU8uWIO_", "outputId": "45294631-684d-45da-e105-909afd3ab632"}, "outputs": [], "source": ["fig, axes = plt.subplots(2, 5, figsize = (11, 4))\n", "for i in range(5):\n", "    rnd_idx = np.random.choice(len(x_train), 1)[0]\n", "    axes[0][i].imshow(x_train[rnd_idx].reshape(64, 64))\n", "    axes[0][i].set_title('observation')\n", "    axes[0][i].axis('off')\n", "    axes[1][i].imshow(y_train[rnd_idx].reshape(64, 64))\n", "    axes[1][i].set_title('denoised image')\n", "    axes[1][i].axis('off')"]}, {"cell_type": "markdown", "metadata": {"id": "rS_jMdvFWIO_"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "vzXAfv8gWIPA"}, "source": ["# 2. Build the network\n", "\n", "The task is to build and train a convolutional autoencoder to remove speckle in images"]}, {"cell_type": "markdown", "metadata": {"id": "sKnZwbkmWIPA"}, "source": ["### The encoder\n", "\n", "The encoder contains three convolutional layers, an input layer with size 64$\\times$64$\\times$1 and one dense layer with size 128:\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# build the encoder\n", "image_input = keras.Input(shape=(64, 64, 1))\n", "#x = layers.Flatten()(image_input)\n", "x = layers.Conv2D(32, 4, 2, padding = 'same')(image_input)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.Activation('relu')(x)\n", "x = layers.Conv2D(32, 4, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.Activation('relu')(x)\n", "x = layers.Conv2D(64, 4, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.Activation('relu')(x)\n", "x = layers.Flatten()(x)\n", "latent_output = layers.Dense(128)(x)\n", "encoder_AE = keras.Model(image_input, latent_output)\n", "encoder_AE.summary()\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 2650, "status": "ok", "timestamp": 1646404779872, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "Xlo-_PBUWIPB", "outputId": "f52057db-b2cf-4b25-b306-636554f5d8ad"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "lSrTT2LwWIPC"}, "source": ["### The decoder\n", "\n", "The decoder contains three transposed convolutional layers and one dense layer that are reciprocal to those of the encoders and one convolutional layer, outputing denoised images with the same size as the input images:\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# build the decoder\n", "latent_input = keras.Input(shape=(128))\n", "x = layers.Dense(4096)(latent_input)\n", "x = layers.Reshape((8, 8, 64), input_shape=(4096,))(x)\n", "x = layers.Conv2DTranspose(64, 4, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.Activation('relu')(x)\n", "x = layers.Conv2DTranspose(32, 4, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.Activation('relu')(x)\n", "x = layers.Conv2DTranspose(32, 4, 2, padding = 'same')(x)\n", "x = layers.BatchNormalization()(x)\n", "x = layers.Activation('relu')(x)\n", "image_output = layers.Conv2D(1, 3, padding = 'same')(x)\n", "\n", "decoder_AE = keras.Model(latent_input, image_output)\n", "decoder_AE.summary()\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 489, "status": "ok", "timestamp": 1646404780359, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "UAnPeplaWIPC", "outputId": "cfc75b09-b67d-4465-e339-3572459ef06e"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "akGDNVhWWIPD"}, "source": ["### The autoencoder\n", "\n", "Joining up the encoder and the decoder, we obtain the AE network:\n", "\n", "**Suggested Answer** \n", "\n", "<details> <summary>Show / Hide</summary> \n", "<p>\n", "    \n", "```python\n", "# build the AE\n", "image_input = keras.Input(shape=(64, 64, 1))\n", "latent = encoder_AE(image_input)\n", "image_output = decoder_AE(latent)\n", "ae_model = keras.Model(image_input, image_output)\n", "ae_model.summary()\n", "\n", "# compile the AE\n", "ae_model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n", "```\n", "    \n", "</p>\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 9, "status": "ok", "timestamp": 1646404780360, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "tU09JbBTWIPD", "outputId": "989a3546-ccf9-4b69-fcb0-96732e7f467e"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "vN8vSQxkWIPE"}, "source": ["### Train the autoencoder"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"elapsed": 144080, "status": "ok", "timestamp": 1646404924866, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "idA6b03xWIPE", "outputId": "1e4b9482-8543-41c5-c4f1-46439df24894"}, "outputs": [], "source": ["# train the AE\n", "ae_model.fit(x_train, y_train, epochs=10, batch_size=64)\n", "            "]}, {"cell_type": "markdown", "metadata": {"id": "gXcCg_amWIPF"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "tj0UH2mbWIPF"}, "source": ["# 3. Analyse results "]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 264}, "executionInfo": {"elapsed": 2613, "status": "ok", "timestamp": 1646404927470, "user": {"displayName": "Jaehoon Cha", "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64", "userId": "15142223743084603318"}, "user_tz": 0}, "id": "t69utdtBWIPF", "outputId": "c785ca3c-366b-4936-eed6-6ead3b327cca"}, "outputs": [], "source": ["y_denoised = ae_model.predict(x_test)\n", "\n", "\n", "fig, axes = plt.subplots(3, 5, figsize = (11, 6))\n", "for i in range(5):\n", "    rnd_idx = np.random.choice(len(x_test), 1)[0]\n", "    axes[0][i].imshow(x_test[rnd_idx].reshape(64, 64))\n", "    axes[0][i].set_title('observation')\n", "    axes[0][i].axis('off')\n", "    axes[1][i].imshow(y_test[rnd_idx].reshape(64, 64))\n", "    axes[1][i].set_title('ground truth')\n", "    axes[1][i].axis('off')\n", "    axes[2][i].imshow(y_denoised[rnd_idx].reshape(64, 64))\n", "    axes[2][i].set_title('denoised by AE')\n", "    axes[2][i].axis('off')"]}, {"cell_type": "markdown", "metadata": {"id": "lfFqzZ3TWIPG"}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {"id": "zcgM4yhgWIPG"}, "source": ["# 4. Exercises\n", "\n", "* Change some hyperparameters in `model.compile()` and `model.fit()` to see their effects (see reference of [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)); \n", "* Change the architeture and activation functions of neural networks to improve the performance\n", "* Add noise to input layer to make the network more robust to noise"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "-DYv69woWIPG"}, "outputs": [], "source": []}], "metadata": {"accelerator": "GPU", "colab": {"collapsed_sections": [], "name": "Physics_Noise removal with autoencoders_solution.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 1}